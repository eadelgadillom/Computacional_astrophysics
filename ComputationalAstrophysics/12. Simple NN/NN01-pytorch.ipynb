{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP+AKgGTKTw0bEdLWhVt0IS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<center>\n","<img src=\"https://i.ibb.co/b3T5hkz/logo.png\" alt=\"logo\" border=\"0\" width=600>\n"],"metadata":{"id":"L-DEKhxYHQQi"}},{"cell_type":"markdown","source":["---\n","## 01. First Neural Network with PyTorch\n","\n","\n","Eduard Larrañaga (ealarranaga@unal.edu.co)\n","\n","---"],"metadata":{"id":"Cv2zWK0RJ-OF"}},{"cell_type":"markdown","source":["### Abstract\n","\n","In this notebook we will implement a simple neural network to represent a linear model using `PyTorch`.\n","\n","---"],"metadata":{"id":"SBp4IDBRKNdo"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"FyyrHWhZExGQ","executionInfo":{"status":"ok","timestamp":1695679865523,"user_tz":300,"elapsed":5924,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b26ac1c1-809b-401c-cbdd-9046140add55"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7e83e5d5bbb0>"]},"metadata":{},"execution_count":1}],"source":["import torch\n","from torch import nn\n","import torch.optim as optim\n","\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib import animation\n","\n","torch.manual_seed(413)"]},{"cell_type":"markdown","source":["## The Dataset\n","\n","We will use a random dataset including 100 temperatures given in Celsius and Fahrenheit degrees."],"metadata":{"id":"pHJvkE2yK4D9"}},{"cell_type":"code","source":["def C2F(c_deg):\n","  return (9/5)*c_deg + 32\n","\n","celsius = np.random.rand(100)*100-50\n","fahrenheit = C2F(celsius)\n"],"metadata":{"id":"tqDAvuaNLHdq","executionInfo":{"status":"ok","timestamp":1695679876465,"user_tz":300,"elapsed":185,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# It is possible to transform the numpy arrays into torch tensors with either\n","# of these commands. Note that the tensors are column vectors of\n","# the float32 type.\n","\n","Ctensor = torch.tensor(celsius, dtype=torch.float32).reshape(-1,1)\n","Ftensor = torch.tensor(fahrenheit, dtype=torch.float32).reshape(-1,1)\n","\n","Ctensor[:10], Ftensor[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"107z4BreWI8O","executionInfo":{"status":"ok","timestamp":1695679926332,"user_tz":300,"elapsed":236,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"174e5508-3cd5-4f19-caa8-3041432d0961"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[-24.4108],\n","         [-43.3100],\n","         [ 42.5065],\n","         [ -8.9440],\n","         [-47.7042],\n","         [-28.9972],\n","         [-39.6220],\n","         [-44.6742],\n","         [-37.9666],\n","         [ 11.0891]]),\n"," tensor([[-11.9394],\n","         [-45.9580],\n","         [108.5117],\n","         [ 15.9008],\n","         [-53.8675],\n","         [-20.1950],\n","         [-39.3196],\n","         [-48.4136],\n","         [-36.3399],\n","         [ 51.9604]]))"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["\n","---\n","\n","## Building our first neural network\n","\n","There are many ways to define a model in PyTorch but, in all cases, we will define it as a function that takes an input and returns an output.\n","\n","The [Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html?highlight=sequential#torch.nn.Sequential) model will define the layers listed out. In this simple example, we will have a number of input features of just 1.\n","\n","As always, the other parameters for each layer or how many layers you need for a model is not an easy question. Often, the best neural network structure is found through a process of trial-and-error experimentation. Generally, you need a network large enough to capture the structure of the problem but small enough to make it fast.\n","\n","We will use dense layers (i.e. fully connected), wich are defined using the [Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) class in PyTorch and the arguments are simply the in_features and the out_features.\n","\n","After each layer, we define the activation function. In this case we may use functions such as the [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html?highlight=relu#torch.nn.ReLU) function or the [Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html?highlight=sigmoid#torch.nn.Sigmoid) function.\n","\n","\n","\n","\n"],"metadata":{"id":"ldl0J-07InOb"}},{"cell_type":"markdown","source":["The first way to create the model is using the class [nn.Sequential()](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html?highlight=sequential#torch.nn.Sequential)"],"metadata":{"id":"Gh65ikvBfVUk"}},{"cell_type":"code","source":["model = nn.Sequential(\n","    nn.Linear(1, 3),\n","    nn.ReLU(),\n","    nn.Linear(3, 3),\n","    nn.ReLU(),\n","    nn.Linear(3, 1),\n","    nn.Sigmoid()\n",")\n","\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zi5EPeiXX3lA","executionInfo":{"status":"ok","timestamp":1695680109285,"user_tz":300,"elapsed":177,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"04a49331-ce68-4953-80c5-9919b44790f7"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequential(\n","  (0): Linear(in_features=1, out_features=3, bias=True)\n","  (1): ReLU()\n","  (2): Linear(in_features=3, out_features=3, bias=True)\n","  (3): ReLU()\n","  (4): Linear(in_features=3, out_features=1, bias=True)\n","  (5): Sigmoid()\n",")\n"]}]},{"cell_type":"markdown","source":["The second way to define the model is as a Python class inherited from the [nn.Module()](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=nn+module#torch.nn.Module).\n","\n","Note that it is needed to call the parent class’s constructor `super().__init__()` to bootstrap your model. It is also needed to define a `.forward()` method to specify how to produce the output tensor, once an input tensor x is provided."],"metadata":{"id":"i48wmYjagF2r"}},{"cell_type":"code","source":["class myNN(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.model = nn.Sequential(nn.Linear(1, 3),\n","                               nn.ReLU(),\n","                               nn.Linear(3, 3),\n","                               nn.ReLU(),\n","                               nn.Linear(3, 1),\n","                               nn.Sigmoid())\n","  def forward(self, x):\n","    output = self.model(x)\n","    return output\n","\n","model = myNN()\n","print(model)"],"metadata":{"id":"Q2rfOEqVJ2c-","executionInfo":{"status":"ok","timestamp":1695680253781,"user_tz":300,"elapsed":266,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"de93d781-f4c1-4f79-f1da-4292965f8805"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["myNN(\n","  (model): Sequential(\n","    (0): Linear(in_features=1, out_features=3, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=3, out_features=3, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=3, out_features=1, bias=True)\n","    (5): Sigmoid()\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["However, it is also possible to define each of the layers in the constructor independently. This may give a great freedom in the way that the output is obtained."],"metadata":{"id":"d9GA2Fczl12a"}},{"cell_type":"code","source":["class myNN(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.layer1 = nn.Linear(1, 3)\n","    self.act1 = nn.ReLU()\n","    self.layer2 = nn.Linear(3, 3)\n","    self.act2 = nn.ReLU()\n","    self.out_layer = nn.Linear(3, 1)\n","    self.out_act = nn.Sigmoid()\n","\n","  def forward(self, x):\n","    x = self.act1(self.layer1(x))\n","    x = self.act2(self.layer2(x))\n","    output = self.out_act(self.out_layer(x))\n","    return output\n","\n","model = myNN()\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KJg-ETAQnozE","executionInfo":{"status":"ok","timestamp":1695680410052,"user_tz":300,"elapsed":211,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"4b7fd0e3-4f4f-4541-d9dc-7a7c02bc3f18"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["myNN(\n","  (layer1): Linear(in_features=1, out_features=3, bias=True)\n","  (act1): ReLU()\n","  (layer2): Linear(in_features=3, out_features=3, bias=True)\n","  (act2): ReLU()\n","  (out_layer): Linear(in_features=3, out_features=1, bias=True)\n","  (out_act): Sigmoid()\n",")\n"]}]},{"cell_type":"markdown","source":["---\n","The next step is to define an 'optimizer' and a 'cost' or 'loss function'.\n","\n","### The Optimizer\n","\n","We will use the [ADAM optimizer](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html?highlight=adam#torch.optim.Adam) but PyTorch includes many more [optimizers](https://pytorch.org/docs/stable/optim.html).\n","\n"],"metadata":{"id":"PraqwI8rO4JB"}},{"cell_type":"code","source":["optimizer = optim.Adam(model.parameters(), lr=0.01)"],"metadata":{"id":"rbGZJH70tyYQ","executionInfo":{"status":"ok","timestamp":1695680543653,"user_tz":300,"elapsed":264,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### The Loss function\n","\n","The loss (or cost) is the function that measures the difference between predictions of the model and known targets. It is also the function that we want to minimize using the optimizer. We will use the [MSELoss](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html?highlight=mse#torch.nn.MSELoss) function.\n","\n","PyTorch includes many more [loss functions](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html?highlight=mse#torch.nn.MSELoss).\n","\n","\n","---\n","\n","#### The Mean-Squared-Error function\n","In this example, we will use the [mean_squared_error](https://keras.io/api/losses/regression_losses/#mean_squared_error-function) loss function, which calculates the mean of the squared errors between targets and predictions."],"metadata":{"id":"BORWO4xE0Rhl"}},{"cell_type":"code","source":["loss_fn = nn.MSELoss()"],"metadata":{"id":"4UF3TNPXE7S3","executionInfo":{"status":"ok","timestamp":1695680592139,"user_tz":300,"elapsed":191,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["---\n","### Training a Model\n","\n","Once the model, the loss metric, and the optimizer are defined, it is time to train the algorithm.\n","\n","In order to train a neural network model, we need to define the number of epochs and the batches,\n","\n","**Epoch**: Number of times that the entire training dataset is passed to the model.\n","\n","**Batch**: Subset of samples passed to the model\n","\n","Hence, the dataset is split into batches and you pass the batches one by one into a model using a training loop. Once you have exhausted all the batches, you have finished one epoch. After that, you can start over again with the same dataset and start the second epoch, continuing to refine the model. The process is repeated until the output of the model is considered satisfactory.\n","\n","Usually, the size of a batch is limited by the system’s memory and the number of computation steps required is linearly proportional to the size of a batch.\n","\n","In PyTorch, it is possible to define a training loop (including two nested for-loops, one for epochs and one for batches).\n","\n","---\n","\n","## The Temperature Transformation Neural Network\n","\n","In our example, we will use the input data `'celsius'` y `'fahrenheit'` to train a linear neural network. Hence we will define 3 layers with no activation functions (i.e. we will use the identitiy function as the activation). Since this set has only 100 samples, we will use 1000 epochs to train the model with a batch of 16 samples."],"metadata":{"id":"tFsFW8PORayl"}},{"cell_type":"code","source":["Xtensor = Ctensor\n","ytensor = Ftensor\n","\n","class myNN(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.layer1 = nn.Linear(1, 3)\n","    self.act1 = nn.Identity()\n","    self.layer2 = nn.Linear(3, 3)\n","    self.act2 = nn.Identity()\n","    self.out_layer = nn.Linear(3, 1)\n","    self.out_act = nn.Identity()\n","\n","  def forward(self, x):\n","    x = self.act1(self.layer1(x))\n","    x = self.act2(self.layer2(x))\n","    output = self.out_act(self.out_layer(x))\n","    return output\n","\n","model = myNN()\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","loss_fn = nn.MSELoss()\n","\n","n_epochs = 1000\n","batch_size = 16\n","history = []\n","for epoch in range(n_epochs):\n","  for i in range(0,len(Xtensor), batch_size):\n","    Xbatch = Xtensor[i:i+batch_size]\n","    ybatch = ytensor[i:i+batch_size]\n","    y_pred = model(Xbatch)\n","    loss = loss_fn(y_pred, ybatch)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","  history.append(loss_fn(model(Xtensor), ytensor).detach().numpy())\n","  print(f'Finished epoch {epoch}, loss:{loss}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mLOaatIuE8ja","executionInfo":{"status":"ok","timestamp":1695681176029,"user_tz":300,"elapsed":8290,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"6fe24398-be50-40c8-bae9-22d45adec73b"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Finished epoch 0, loss:949.2785034179688\n","Finished epoch 1, loss:929.5601806640625\n","Finished epoch 2, loss:911.3406982421875\n","Finished epoch 3, loss:894.202880859375\n","Finished epoch 4, loss:877.559326171875\n","Finished epoch 5, loss:860.8219604492188\n","Finished epoch 6, loss:843.5563354492188\n","Finished epoch 7, loss:825.5252075195312\n","Finished epoch 8, loss:806.6227416992188\n","Finished epoch 9, loss:786.8109741210938\n","Finished epoch 10, loss:766.0881958007812\n","Finished epoch 11, loss:744.4793090820312\n","Finished epoch 12, loss:722.0302124023438\n","Finished epoch 13, loss:698.8045043945312\n","Finished epoch 14, loss:674.8807373046875\n","Finished epoch 15, loss:650.3489990234375\n","Finished epoch 16, loss:625.3090209960938\n","Finished epoch 17, loss:599.8676147460938\n","Finished epoch 18, loss:574.1373291015625\n","Finished epoch 19, loss:548.2349243164062\n","Finished epoch 20, loss:522.2811279296875\n","Finished epoch 21, loss:496.4006652832031\n","Finished epoch 22, loss:470.7234802246094\n","Finished epoch 23, loss:445.3857727050781\n","Finished epoch 24, loss:420.53228759765625\n","Finished epoch 25, loss:396.3183898925781\n","Finished epoch 26, loss:372.91192626953125\n","Finished epoch 27, loss:350.4950256347656\n","Finished epoch 28, loss:329.26495361328125\n","Finished epoch 29, loss:309.43304443359375\n","Finished epoch 30, loss:291.2233581542969\n","Finished epoch 31, loss:274.8687744140625\n","Finished epoch 32, loss:260.6066589355469\n","Finished epoch 33, loss:248.67166137695312\n","Finished epoch 34, loss:239.288818359375\n","Finished epoch 35, loss:232.6634521484375\n","Finished epoch 36, loss:228.97164916992188\n","Finished epoch 37, loss:228.34930419921875\n","Finished epoch 38, loss:230.88113403320312\n","Finished epoch 39, loss:236.59091186523438\n","Finished epoch 40, loss:245.43258666992188\n","Finished epoch 41, loss:257.2846374511719\n","Finished epoch 42, loss:271.9471130371094\n","Finished epoch 43, loss:289.1432800292969\n","Finished epoch 44, loss:308.52606201171875\n","Finished epoch 45, loss:329.68896484375\n","Finished epoch 46, loss:352.1819763183594\n","Finished epoch 47, loss:375.53009033203125\n","Finished epoch 48, loss:399.25445556640625\n","Finished epoch 49, loss:422.89306640625\n","Finished epoch 50, loss:446.02166748046875\n","Finished epoch 51, loss:468.2685241699219\n","Finished epoch 52, loss:489.327392578125\n","Finished epoch 53, loss:508.96295166015625\n","Finished epoch 54, loss:527.0123291015625\n","Finished epoch 55, loss:543.383056640625\n","Finished epoch 56, loss:558.04296875\n","Finished epoch 57, loss:571.013671875\n","Finished epoch 58, loss:582.3583984375\n","Finished epoch 59, loss:592.170654296875\n","Finished epoch 60, loss:600.5656127929688\n","Finished epoch 61, loss:607.6691284179688\n","Finished epoch 62, loss:613.6123657226562\n","Finished epoch 63, loss:618.5250854492188\n","Finished epoch 64, loss:622.5307006835938\n","Finished epoch 65, loss:625.7451782226562\n","Finished epoch 66, loss:628.27587890625\n","Finished epoch 67, loss:630.2176513671875\n","Finished epoch 68, loss:631.6558837890625\n","Finished epoch 69, loss:632.6654663085938\n","Finished epoch 70, loss:633.31103515625\n","Finished epoch 71, loss:633.64892578125\n","Finished epoch 72, loss:633.7275390625\n","Finished epoch 73, loss:633.58837890625\n","Finished epoch 74, loss:633.265380859375\n","Finished epoch 75, loss:632.7884521484375\n","Finished epoch 76, loss:632.182373046875\n","Finished epoch 77, loss:631.4683227539062\n","Finished epoch 78, loss:630.6632080078125\n","Finished epoch 79, loss:629.781982421875\n","Finished epoch 80, loss:628.8369140625\n","Finished epoch 81, loss:627.8377075195312\n","Finished epoch 82, loss:626.7930908203125\n","Finished epoch 83, loss:625.7100830078125\n","Finished epoch 84, loss:624.5940551757812\n","Finished epoch 85, loss:623.4500732421875\n","Finished epoch 86, loss:622.282470703125\n","Finished epoch 87, loss:621.0939331054688\n","Finished epoch 88, loss:619.8867797851562\n","Finished epoch 89, loss:618.6641235351562\n","Finished epoch 90, loss:617.4273681640625\n","Finished epoch 91, loss:616.177978515625\n","Finished epoch 92, loss:614.9171142578125\n","Finished epoch 93, loss:613.64599609375\n","Finished epoch 94, loss:612.3650512695312\n","Finished epoch 95, loss:611.0755004882812\n","Finished epoch 96, loss:609.7772216796875\n","Finished epoch 97, loss:608.4710693359375\n","Finished epoch 98, loss:607.1567993164062\n","Finished epoch 99, loss:605.8353271484375\n","Finished epoch 100, loss:604.5068359375\n","Finished epoch 101, loss:603.1710815429688\n","Finished epoch 102, loss:601.828125\n","Finished epoch 103, loss:600.4782104492188\n","Finished epoch 104, loss:599.121337890625\n","Finished epoch 105, loss:597.7573852539062\n","Finished epoch 106, loss:596.3870239257812\n","Finished epoch 107, loss:595.0094604492188\n","Finished epoch 108, loss:593.625\n","Finished epoch 109, loss:592.2332763671875\n","Finished epoch 110, loss:590.8346557617188\n","Finished epoch 111, loss:589.4290161132812\n","Finished epoch 112, loss:588.0161743164062\n","Finished epoch 113, loss:586.5958251953125\n","Finished epoch 114, loss:585.1685791015625\n","Finished epoch 115, loss:583.7338256835938\n","Finished epoch 116, loss:582.2916259765625\n","Finished epoch 117, loss:580.8421630859375\n","Finished epoch 118, loss:579.38525390625\n","Finished epoch 119, loss:577.9201049804688\n","Finished epoch 120, loss:576.4474487304688\n","Finished epoch 121, loss:574.9668579101562\n","Finished epoch 122, loss:573.4780883789062\n","Finished epoch 123, loss:571.9812622070312\n","Finished epoch 124, loss:570.476318359375\n","Finished epoch 125, loss:568.9631958007812\n","Finished epoch 126, loss:567.4413452148438\n","Finished epoch 127, loss:565.9111328125\n","Finished epoch 128, loss:564.3724365234375\n","Finished epoch 129, loss:562.824951171875\n","Finished epoch 130, loss:561.2689819335938\n","Finished epoch 131, loss:559.7037353515625\n","Finished epoch 132, loss:558.1295776367188\n","Finished epoch 133, loss:556.5463256835938\n","Finished epoch 134, loss:554.953857421875\n","Finished epoch 135, loss:553.35205078125\n","Finished epoch 136, loss:551.74072265625\n","Finished epoch 137, loss:550.1201171875\n","Finished epoch 138, loss:548.48974609375\n","Finished epoch 139, loss:546.849853515625\n","Finished epoch 140, loss:545.199951171875\n","Finished epoch 141, loss:543.5398559570312\n","Finished epoch 142, loss:541.8697509765625\n","Finished epoch 143, loss:540.1895751953125\n","Finished epoch 144, loss:538.4990844726562\n","Finished epoch 145, loss:536.7982177734375\n","Finished epoch 146, loss:535.08642578125\n","Finished epoch 147, loss:533.3641357421875\n","Finished epoch 148, loss:531.631103515625\n","Finished epoch 149, loss:529.88720703125\n","Finished epoch 150, loss:528.1325073242188\n","Finished epoch 151, loss:526.3665771484375\n","Finished epoch 152, loss:524.5896606445312\n","Finished epoch 153, loss:522.8011474609375\n","Finished epoch 154, loss:521.001220703125\n","Finished epoch 155, loss:519.1893310546875\n","Finished epoch 156, loss:517.365966796875\n","Finished epoch 157, loss:515.5305786132812\n","Finished epoch 158, loss:513.6835327148438\n","Finished epoch 159, loss:511.823974609375\n","Finished epoch 160, loss:509.95263671875\n","Finished epoch 161, loss:508.0687255859375\n","Finished epoch 162, loss:506.17254638671875\n","Finished epoch 163, loss:504.2635192871094\n","Finished epoch 164, loss:502.342041015625\n","Finished epoch 165, loss:500.4078369140625\n","Finished epoch 166, loss:498.46044921875\n","Finished epoch 167, loss:496.50030517578125\n","Finished epoch 168, loss:494.5269775390625\n","Finished epoch 169, loss:492.5404052734375\n","Finished epoch 170, loss:490.540283203125\n","Finished epoch 171, loss:488.52679443359375\n","Finished epoch 172, loss:486.4994201660156\n","Finished epoch 173, loss:484.4586486816406\n","Finished epoch 174, loss:482.4038391113281\n","Finished epoch 175, loss:480.3350830078125\n","Finished epoch 176, loss:478.252197265625\n","Finished epoch 177, loss:476.15521240234375\n","Finished epoch 178, loss:474.04400634765625\n","Finished epoch 179, loss:471.918212890625\n","Finished epoch 180, loss:469.77783203125\n","Finished epoch 181, loss:467.62286376953125\n","Finished epoch 182, loss:465.45318603515625\n","Finished epoch 183, loss:463.268310546875\n","Finished epoch 184, loss:461.0692138671875\n","Finished epoch 185, loss:458.85443115234375\n","Finished epoch 186, loss:456.6246337890625\n","Finished epoch 187, loss:454.3797302246094\n","Finished epoch 188, loss:452.1190185546875\n","Finished epoch 189, loss:449.843017578125\n","Finished epoch 190, loss:447.5513916015625\n","Finished epoch 191, loss:445.2442932128906\n","Finished epoch 192, loss:442.9215087890625\n","Finished epoch 193, loss:440.5830078125\n","Finished epoch 194, loss:438.228271484375\n","Finished epoch 195, loss:435.85797119140625\n","Finished epoch 196, loss:433.4714660644531\n","Finished epoch 197, loss:431.06878662109375\n","Finished epoch 198, loss:428.64984130859375\n","Finished epoch 199, loss:426.2146301269531\n","Finished epoch 200, loss:423.76318359375\n","Finished epoch 201, loss:421.29522705078125\n","Finished epoch 202, loss:418.8106994628906\n","Finished epoch 203, loss:416.309814453125\n","Finished epoch 204, loss:413.79241943359375\n","Finished epoch 205, loss:411.2587890625\n","Finished epoch 206, loss:408.708251953125\n","Finished epoch 207, loss:406.1410217285156\n","Finished epoch 208, loss:403.5572814941406\n","Finished epoch 209, loss:400.95684814453125\n","Finished epoch 210, loss:398.33978271484375\n","Finished epoch 211, loss:395.7060546875\n","Finished epoch 212, loss:393.05548095703125\n","Finished epoch 213, loss:390.3883972167969\n","Finished epoch 214, loss:387.7046813964844\n","Finished epoch 215, loss:385.0041809082031\n","Finished epoch 216, loss:382.28729248046875\n","Finished epoch 217, loss:379.5537109375\n","Finished epoch 218, loss:376.8037109375\n","Finished epoch 219, loss:374.0369873046875\n","Finished epoch 220, loss:371.2540588378906\n","Finished epoch 221, loss:368.45489501953125\n","Finished epoch 222, loss:365.639404296875\n","Finished epoch 223, loss:362.8078918457031\n","Finished epoch 224, loss:359.9603271484375\n","Finished epoch 225, loss:357.0964050292969\n","Finished epoch 226, loss:354.21722412109375\n","Finished epoch 227, loss:351.3218688964844\n","Finished epoch 228, loss:348.4111328125\n","Finished epoch 229, loss:345.4848327636719\n","Finished epoch 230, loss:342.54315185546875\n","Finished epoch 231, loss:339.586669921875\n","Finished epoch 232, loss:336.61517333984375\n","Finished epoch 233, loss:333.6291198730469\n","Finished epoch 234, loss:330.6286926269531\n","Finished epoch 235, loss:327.61383056640625\n","Finished epoch 236, loss:324.58502197265625\n","Finished epoch 237, loss:321.54217529296875\n","Finished epoch 238, loss:318.4861145019531\n","Finished epoch 239, loss:315.4165954589844\n","Finished epoch 240, loss:312.3340759277344\n","Finished epoch 241, loss:309.239013671875\n","Finished epoch 242, loss:306.13153076171875\n","Finished epoch 243, loss:303.01214599609375\n","Finished epoch 244, loss:299.88104248046875\n","Finished epoch 245, loss:296.73834228515625\n","Finished epoch 246, loss:293.5848388671875\n","Finished epoch 247, loss:290.4205322265625\n","Finished epoch 248, loss:287.24627685546875\n","Finished epoch 249, loss:284.0621337890625\n","Finished epoch 250, loss:280.86865234375\n","Finished epoch 251, loss:277.6665344238281\n","Finished epoch 252, loss:274.4557800292969\n","Finished epoch 253, loss:271.23712158203125\n","Finished epoch 254, loss:268.01104736328125\n","Finished epoch 255, loss:264.7781677246094\n","Finished epoch 256, loss:261.538818359375\n","Finished epoch 257, loss:258.29345703125\n","Finished epoch 258, loss:255.04275512695312\n","Finished epoch 259, loss:251.78729248046875\n","Finished epoch 260, loss:248.527587890625\n","Finished epoch 261, loss:245.26443481445312\n","Finished epoch 262, loss:241.9983367919922\n","Finished epoch 263, loss:238.72967529296875\n","Finished epoch 264, loss:235.4593505859375\n","Finished epoch 265, loss:232.1877899169922\n","Finished epoch 266, loss:228.91598510742188\n","Finished epoch 267, loss:225.6443328857422\n","Finished epoch 268, loss:222.37387084960938\n","Finished epoch 269, loss:219.10488891601562\n","Finished epoch 270, loss:215.83847045898438\n","Finished epoch 271, loss:212.5750274658203\n","Finished epoch 272, loss:209.31527709960938\n","Finished epoch 273, loss:206.06033325195312\n","Finished epoch 274, loss:202.81082153320312\n","Finished epoch 275, loss:199.56735229492188\n","Finished epoch 276, loss:196.33065795898438\n","Finished epoch 277, loss:193.10159301757812\n","Finished epoch 278, loss:189.88116455078125\n","Finished epoch 279, loss:186.6699981689453\n","Finished epoch 280, loss:183.468994140625\n","Finished epoch 281, loss:180.27883911132812\n","Finished epoch 282, loss:177.10040283203125\n","Finished epoch 283, loss:173.93450927734375\n","Finished epoch 284, loss:170.78207397460938\n","Finished epoch 285, loss:167.643798828125\n","Finished epoch 286, loss:164.5205535888672\n","Finished epoch 287, loss:161.41299438476562\n","Finished epoch 288, loss:158.322265625\n","Finished epoch 289, loss:155.24903869628906\n","Finished epoch 290, loss:152.19412231445312\n","Finished epoch 291, loss:149.15835571289062\n","Finished epoch 292, loss:146.1425323486328\n","Finished epoch 293, loss:143.14759826660156\n","Finished epoch 294, loss:140.17410278320312\n","Finished epoch 295, loss:137.22296142578125\n","Finished epoch 296, loss:134.294921875\n","Finished epoch 297, loss:131.39089965820312\n","Finished epoch 298, loss:128.51153564453125\n","Finished epoch 299, loss:125.6578140258789\n","Finished epoch 300, loss:122.83026123046875\n","Finished epoch 301, loss:120.02957153320312\n","Finished epoch 302, loss:117.25660705566406\n","Finished epoch 303, loss:114.51190948486328\n","Finished epoch 304, loss:111.79627227783203\n","Finished epoch 305, loss:109.1104736328125\n","Finished epoch 306, loss:106.45497131347656\n","Finished epoch 307, loss:103.83061218261719\n","Finished epoch 308, loss:101.23777770996094\n","Finished epoch 309, loss:98.67711639404297\n","Finished epoch 310, loss:96.14923858642578\n","Finished epoch 311, loss:93.6546630859375\n","Finished epoch 312, loss:91.19397735595703\n","Finished epoch 313, loss:88.76776123046875\n","Finished epoch 314, loss:86.37630462646484\n","Finished epoch 315, loss:84.0200424194336\n","Finished epoch 316, loss:81.69959259033203\n","Finished epoch 317, loss:79.41519165039062\n","Finished epoch 318, loss:77.16720581054688\n","Finished epoch 319, loss:74.95591735839844\n","Finished epoch 320, loss:72.78187561035156\n","Finished epoch 321, loss:70.64512634277344\n","Finished epoch 322, loss:68.54595947265625\n","Finished epoch 323, loss:66.48472595214844\n","Finished epoch 324, loss:64.46160888671875\n","Finished epoch 325, loss:62.476661682128906\n","Finished epoch 326, loss:60.530052185058594\n","Finished epoch 327, loss:58.62202072143555\n","Finished epoch 328, loss:56.75247573852539\n","Finished epoch 329, loss:54.921539306640625\n","Finished epoch 330, loss:53.129188537597656\n","Finished epoch 331, loss:51.37542724609375\n","Finished epoch 332, loss:49.66020202636719\n","Finished epoch 333, loss:47.98353958129883\n","Finished epoch 334, loss:46.34500503540039\n","Finished epoch 335, loss:44.74482727050781\n","Finished epoch 336, loss:43.182777404785156\n","Finished epoch 337, loss:41.6585693359375\n","Finished epoch 338, loss:40.17206573486328\n","Finished epoch 339, loss:38.72304916381836\n","Finished epoch 340, loss:37.31110382080078\n","Finished epoch 341, loss:35.936065673828125\n","Finished epoch 342, loss:34.59758377075195\n","Finished epoch 343, loss:33.2952766418457\n","Finished epoch 344, loss:32.028892517089844\n","Finished epoch 345, loss:30.797950744628906\n","Finished epoch 346, loss:29.60207176208496\n","Finished epoch 347, loss:28.44088363647461\n","Finished epoch 348, loss:27.313892364501953\n","Finished epoch 349, loss:26.2205753326416\n","Finished epoch 350, loss:25.160457611083984\n","Finished epoch 351, loss:24.13313865661621\n","Finished epoch 352, loss:23.138080596923828\n","Finished epoch 353, loss:22.174707412719727\n","Finished epoch 354, loss:21.242460250854492\n","Finished epoch 355, loss:20.340749740600586\n","Finished epoch 356, loss:19.46915626525879\n","Finished epoch 357, loss:18.62700843811035\n","Finished epoch 358, loss:17.81377410888672\n","Finished epoch 359, loss:17.02880096435547\n","Finished epoch 360, loss:16.271562576293945\n","Finished epoch 361, loss:15.541358947753906\n","Finished epoch 362, loss:14.837554931640625\n","Finished epoch 363, loss:14.15964126586914\n","Finished epoch 364, loss:13.50700569152832\n","Finished epoch 365, loss:12.87894344329834\n","Finished epoch 366, loss:12.274862289428711\n","Finished epoch 367, loss:11.694201469421387\n","Finished epoch 368, loss:11.136251449584961\n","Finished epoch 369, loss:10.600433349609375\n","Finished epoch 370, loss:10.086082458496094\n","Finished epoch 371, loss:9.592671394348145\n","Finished epoch 372, loss:9.119515419006348\n","Finished epoch 373, loss:8.666017532348633\n","Finished epoch 374, loss:8.231595993041992\n","Finished epoch 375, loss:7.815650939941406\n","Finished epoch 376, loss:7.417572021484375\n","Finished epoch 377, loss:7.036825656890869\n","Finished epoch 378, loss:6.6728291511535645\n","Finished epoch 379, loss:6.32503604888916\n","Finished epoch 380, loss:5.992874622344971\n","Finished epoch 381, loss:5.675752639770508\n","Finished epoch 382, loss:5.373159408569336\n","Finished epoch 383, loss:5.084610939025879\n","Finished epoch 384, loss:4.80956506729126\n","Finished epoch 385, loss:4.547545433044434\n","Finished epoch 386, loss:4.298003196716309\n","Finished epoch 387, loss:4.06047248840332\n","Finished epoch 388, loss:3.834505558013916\n","Finished epoch 389, loss:3.6196508407592773\n","Finished epoch 390, loss:3.4154207706451416\n","Finished epoch 391, loss:3.2214202880859375\n","Finished epoch 392, loss:3.0372071266174316\n","Finished epoch 393, loss:2.8623576164245605\n","Finished epoch 394, loss:2.6964914798736572\n","Finished epoch 395, loss:2.5392143726348877\n","Finished epoch 396, loss:2.390151262283325\n","Finished epoch 397, loss:2.248947858810425\n","Finished epoch 398, loss:2.1152360439300537\n","Finished epoch 399, loss:1.9886977672576904\n","Finished epoch 400, loss:1.8689751625061035\n","Finished epoch 401, loss:1.75575590133667\n","Finished epoch 402, loss:1.6487672328948975\n","Finished epoch 403, loss:1.5476917028427124\n","Finished epoch 404, loss:1.4522323608398438\n","Finished epoch 405, loss:1.3621408939361572\n","Finished epoch 406, loss:1.2771406173706055\n","Finished epoch 407, loss:1.196974277496338\n","Finished epoch 408, loss:1.1214147806167603\n","Finished epoch 409, loss:1.0502283573150635\n","Finished epoch 410, loss:0.9831815361976624\n","Finished epoch 411, loss:0.9200568795204163\n","Finished epoch 412, loss:0.8606575131416321\n","Finished epoch 413, loss:0.8047774434089661\n","Finished epoch 414, loss:0.7522572875022888\n","Finished epoch 415, loss:0.7029052376747131\n","Finished epoch 416, loss:0.6565372943878174\n","Finished epoch 417, loss:0.6129891872406006\n","Finished epoch 418, loss:0.5721212029457092\n","Finished epoch 419, loss:0.5337843894958496\n","Finished epoch 420, loss:0.49782103300094604\n","Finished epoch 421, loss:0.46412014961242676\n","Finished epoch 422, loss:0.4325408339500427\n","Finished epoch 423, loss:0.4029521942138672\n","Finished epoch 424, loss:0.3752442002296448\n","Finished epoch 425, loss:0.34931960701942444\n","Finished epoch 426, loss:0.3250698745250702\n","Finished epoch 427, loss:0.3023919463157654\n","Finished epoch 428, loss:0.2811906933784485\n","Finished epoch 429, loss:0.26138192415237427\n","Finished epoch 430, loss:0.24288085103034973\n","Finished epoch 431, loss:0.2256113588809967\n","Finished epoch 432, loss:0.20949187874794006\n","Finished epoch 433, loss:0.19444386661052704\n","Finished epoch 434, loss:0.18041253089904785\n","Finished epoch 435, loss:0.16734245419502258\n","Finished epoch 436, loss:0.15515831112861633\n","Finished epoch 437, loss:0.1438106894493103\n","Finished epoch 438, loss:0.13324642181396484\n","Finished epoch 439, loss:0.12341386079788208\n","Finished epoch 440, loss:0.1142626479268074\n","Finished epoch 441, loss:0.1057511642575264\n","Finished epoch 442, loss:0.09784378856420517\n","Finished epoch 443, loss:0.09049149602651596\n","Finished epoch 444, loss:0.0836661085486412\n","Finished epoch 445, loss:0.07732271403074265\n","Finished epoch 446, loss:0.0714382603764534\n","Finished epoch 447, loss:0.06597641855478287\n","Finished epoch 448, loss:0.06090989708900452\n","Finished epoch 449, loss:0.0562114492058754\n","Finished epoch 450, loss:0.05185887962579727\n","Finished epoch 451, loss:0.04782508313655853\n","Finished epoch 452, loss:0.044091589748859406\n","Finished epoch 453, loss:0.04063327610492706\n","Finished epoch 454, loss:0.03743403032422066\n","Finished epoch 455, loss:0.03447456285357475\n","Finished epoch 456, loss:0.03173472359776497\n","Finished epoch 457, loss:0.02920224331319332\n","Finished epoch 458, loss:0.02686348371207714\n","Finished epoch 459, loss:0.024705585092306137\n","Finished epoch 460, loss:0.022710785269737244\n","Finished epoch 461, loss:0.020868975669145584\n","Finished epoch 462, loss:0.01917004957795143\n","Finished epoch 463, loss:0.017603065818548203\n","Finished epoch 464, loss:0.016159556806087494\n","Finished epoch 465, loss:0.01482931338250637\n","Finished epoch 466, loss:0.013602521270513535\n","Finished epoch 467, loss:0.012472440488636494\n","Finished epoch 468, loss:0.01143260020762682\n","Finished epoch 469, loss:0.010476306080818176\n","Finished epoch 470, loss:0.009594898670911789\n","Finished epoch 471, loss:0.00878460705280304\n","Finished epoch 472, loss:0.008040808141231537\n","Finished epoch 473, loss:0.0073555572889745235\n","Finished epoch 474, loss:0.006727628409862518\n","Finished epoch 475, loss:0.006150778383016586\n","Finished epoch 476, loss:0.005622906610369682\n","Finished epoch 477, loss:0.005137319676578045\n","Finished epoch 478, loss:0.0046916319988667965\n","Finished epoch 479, loss:0.00428191851824522\n","Finished epoch 480, loss:0.003907634876668453\n","Finished epoch 481, loss:0.003564688842743635\n","Finished epoch 482, loss:0.0032505185808986425\n","Finished epoch 483, loss:0.0029627662152051926\n","Finished epoch 484, loss:0.002699539065361023\n","Finished epoch 485, loss:0.002459033392369747\n","Finished epoch 486, loss:0.0022391281090676785\n","Finished epoch 487, loss:0.0020378611516207457\n","Finished epoch 488, loss:0.0018542567268013954\n","Finished epoch 489, loss:0.0016862342599779367\n","Finished epoch 490, loss:0.001533006550744176\n","Finished epoch 491, loss:0.001393427955918014\n","Finished epoch 492, loss:0.0012661615619435906\n","Finished epoch 493, loss:0.0011498775565996766\n","Finished epoch 494, loss:0.0010433383285999298\n","Finished epoch 495, loss:0.0009469551732763648\n","Finished epoch 496, loss:0.0008590579382143915\n","Finished epoch 497, loss:0.0007788333459757268\n","Finished epoch 498, loss:0.0007055954192765057\n","Finished epoch 499, loss:0.0006391196511685848\n","Finished epoch 500, loss:0.0005789613351225853\n","Finished epoch 501, loss:0.0005239956662990153\n","Finished epoch 502, loss:0.0004744141479022801\n","Finished epoch 503, loss:0.0004293753008823842\n","Finished epoch 504, loss:0.00038802571361884475\n","Finished epoch 505, loss:0.0003505423082970083\n","Finished epoch 506, loss:0.0003168477560393512\n","Finished epoch 507, loss:0.0002860931563191116\n","Finished epoch 508, loss:0.00025826384080573916\n","Finished epoch 509, loss:0.00023331333068199456\n","Finished epoch 510, loss:0.00021036747784819454\n","Finished epoch 511, loss:0.00018957002612296492\n","Finished epoch 512, loss:0.00017076083167921752\n","Finished epoch 513, loss:0.00015385249571409076\n","Finished epoch 514, loss:0.00013836147263646126\n","Finished epoch 515, loss:0.00012469675857573748\n","Finished epoch 516, loss:0.00011224332411075011\n","Finished epoch 517, loss:0.00010079552885144949\n","Finished epoch 518, loss:9.07140492927283e-05\n","Finished epoch 519, loss:8.158337732311338e-05\n","Finished epoch 520, loss:7.326079503400251e-05\n","Finished epoch 521, loss:6.587756797671318e-05\n","Finished epoch 522, loss:5.899967436562292e-05\n","Finished epoch 523, loss:5.290348417474888e-05\n","Finished epoch 524, loss:4.7540317609673366e-05\n","Finished epoch 525, loss:4.257598993717693e-05\n","Finished epoch 526, loss:3.822826693067327e-05\n","Finished epoch 527, loss:3.4178294299636036e-05\n","Finished epoch 528, loss:3.0664603400509804e-05\n","Finished epoch 529, loss:2.7449277695268393e-05\n","Finished epoch 530, loss:2.4484877940267324e-05\n","Finished epoch 531, loss:2.191812927776482e-05\n","Finished epoch 532, loss:1.953986611624714e-05\n","Finished epoch 533, loss:1.746156340232119e-05\n","Finished epoch 534, loss:1.5617217286489904e-05\n","Finished epoch 535, loss:1.3935270544607192e-05\n","Finished epoch 536, loss:1.2397844329825602e-05\n","Finished epoch 537, loss:1.1029535926354583e-05\n","Finished epoch 538, loss:9.848284207691904e-06\n","Finished epoch 539, loss:8.797600457910448e-06\n","Finished epoch 540, loss:7.807462679920718e-06\n","Finished epoch 541, loss:6.9492371039814316e-06\n","Finished epoch 542, loss:6.203423708939226e-06\n","Finished epoch 543, loss:5.529598638531752e-06\n","Finished epoch 544, loss:4.909417839371599e-06\n","Finished epoch 545, loss:4.353827534941956e-06\n","Finished epoch 546, loss:3.863639904011507e-06\n","Finished epoch 547, loss:3.4312506613787264e-06\n","Finished epoch 548, loss:3.0534961297234986e-06\n","Finished epoch 549, loss:2.7079124720330583e-06\n","Finished epoch 550, loss:2.4080375169432955e-06\n","Finished epoch 551, loss:2.137995124940062e-06\n","Finished epoch 552, loss:1.8984277403433225e-06\n","Finished epoch 553, loss:1.6829154674269375e-06\n","Finished epoch 554, loss:1.4786267001909437e-06\n","Finished epoch 555, loss:1.3047813354205573e-06\n","Finished epoch 556, loss:1.1463177997939056e-06\n","Finished epoch 557, loss:1.0178420097872731e-06\n","Finished epoch 558, loss:9.032548859977396e-07\n","Finished epoch 559, loss:7.939947863633279e-07\n","Finished epoch 560, loss:7.082217621245945e-07\n","Finished epoch 561, loss:6.34015805189847e-07\n","Finished epoch 562, loss:5.625973358291958e-07\n","Finished epoch 563, loss:4.919756975141354e-07\n","Finished epoch 564, loss:4.3144063965883106e-07\n","Finished epoch 565, loss:3.779525741265388e-07\n","Finished epoch 566, loss:3.3038895708159544e-07\n","Finished epoch 567, loss:2.853726073226426e-07\n","Finished epoch 568, loss:2.403039616183378e-07\n","Finished epoch 569, loss:2.1215602430402214e-07\n","Finished epoch 570, loss:1.836945671129797e-07\n","Finished epoch 571, loss:1.592365066471757e-07\n","Finished epoch 572, loss:1.3482157612543233e-07\n","Finished epoch 573, loss:1.1453063564204058e-07\n","Finished epoch 574, loss:9.764688968516566e-08\n","Finished epoch 575, loss:8.612086332959734e-08\n","Finished epoch 576, loss:7.518634959069459e-08\n","Finished epoch 577, loss:6.89656332042432e-08\n","Finished epoch 578, loss:6.430026644466125e-08\n","Finished epoch 579, loss:6.048345824183343e-08\n","Finished epoch 580, loss:5.5193268622133473e-08\n","Finished epoch 581, loss:5.121172819144704e-08\n","Finished epoch 582, loss:4.737934489185136e-08\n","Finished epoch 583, loss:4.5672905457649904e-08\n","Finished epoch 584, loss:4.351501559085591e-08\n","Finished epoch 585, loss:4.121467611639673e-08\n","Finished epoch 586, loss:3.7621489923367335e-08\n","Finished epoch 587, loss:3.534320569542615e-08\n","Finished epoch 588, loss:3.448418794960162e-08\n","Finished epoch 589, loss:3.293224892786384e-08\n","Finished epoch 590, loss:3.1760706065142585e-08\n","Finished epoch 591, loss:3.0673064088659885e-08\n","Finished epoch 592, loss:2.9314506377886573e-08\n","Finished epoch 593, loss:2.7783599421127292e-08\n","Finished epoch 594, loss:2.6704597644311434e-08\n","Finished epoch 595, loss:2.636524243371241e-08\n","Finished epoch 596, loss:2.651496799899178e-08\n","Finished epoch 597, loss:2.5752811438906065e-08\n","Finished epoch 598, loss:2.510036267722171e-08\n","Finished epoch 599, loss:2.4669375875419064e-08\n","Finished epoch 600, loss:2.4246574525932374e-08\n","Finished epoch 601, loss:2.4246574525932374e-08\n","Finished epoch 602, loss:2.396497222889593e-08\n","Finished epoch 603, loss:2.388107134265738e-08\n","Finished epoch 604, loss:2.4326837433363835e-08\n","Finished epoch 605, loss:2.3293310391636624e-08\n","Finished epoch 606, loss:2.3216117028823646e-08\n","Finished epoch 607, loss:2.2571626345779805e-08\n","Finished epoch 608, loss:2.2313329850476293e-08\n","Finished epoch 609, loss:2.215053029885894e-08\n","Finished epoch 610, loss:2.2112786268735363e-08\n","Finished epoch 611, loss:2.199443827066716e-08\n","Finished epoch 612, loss:2.130720133663999e-08\n","Finished epoch 613, loss:2.1399060301519057e-08\n","Finished epoch 614, loss:2.1208975908848515e-08\n","Finished epoch 615, loss:2.056221148905024e-08\n","Finished epoch 616, loss:2.0380312548695656e-08\n","Finished epoch 617, loss:2.0504685949163104e-08\n","Finished epoch 618, loss:1.9798577000074147e-08\n","Finished epoch 619, loss:1.969114293842722e-08\n","Finished epoch 620, loss:1.9823133357022016e-08\n","Finished epoch 621, loss:1.9740141965485236e-08\n","Finished epoch 622, loss:1.9432846443123708e-08\n","Finished epoch 623, loss:1.8682172253647877e-08\n","Finished epoch 624, loss:1.8855772054848785e-08\n","Finished epoch 625, loss:1.8533015122557117e-08\n","Finished epoch 626, loss:1.8219580510958622e-08\n","Finished epoch 627, loss:1.84487731758054e-08\n","Finished epoch 628, loss:1.8370215570939763e-08\n","Finished epoch 629, loss:1.7704010701891093e-08\n","Finished epoch 630, loss:1.7704010701891093e-08\n","Finished epoch 631, loss:1.77608541207519e-08\n","Finished epoch 632, loss:1.716695408049418e-08\n","Finished epoch 633, loss:1.693139495273499e-08\n","Finished epoch 634, loss:1.6606591657364334e-08\n","Finished epoch 635, loss:1.629474866149394e-08\n","Finished epoch 636, loss:1.6257232005045807e-08\n","Finished epoch 637, loss:1.6123422597047465e-08\n","Finished epoch 638, loss:1.5639457728866546e-08\n","Finished epoch 639, loss:1.5508376804973523e-08\n","Finished epoch 640, loss:1.5508376804973523e-08\n","Finished epoch 641, loss:1.504601243595971e-08\n","Finished epoch 642, loss:1.518675674105907e-08\n","Finished epoch 643, loss:1.4382763424691802e-08\n","Finished epoch 644, loss:1.4086495525589271e-08\n","Finished epoch 645, loss:1.4633442901867966e-08\n","Finished epoch 646, loss:1.4503385159514437e-08\n","Finished epoch 647, loss:1.4095931533120165e-08\n","Finished epoch 648, loss:1.3814215549246e-08\n","Finished epoch 649, loss:1.3466333825817856e-08\n","Finished epoch 650, loss:1.34371163085234e-08\n","Finished epoch 651, loss:1.351169487406878e-08\n","Finished epoch 652, loss:1.325351206560299e-08\n","Finished epoch 653, loss:1.2940986948706268e-08\n","Finished epoch 654, loss:1.2822184203287179e-08\n","Finished epoch 655, loss:1.2704290952569863e-08\n","Finished epoch 656, loss:1.2257956427674799e-08\n","Finished epoch 657, loss:1.2001592608612555e-08\n","Finished epoch 658, loss:1.2005344274257368e-08\n","Finished epoch 659, loss:1.1705324709510023e-08\n","Finished epoch 660, loss:1.1773536812142993e-08\n","Finished epoch 661, loss:1.161085094736336e-08\n","Finished epoch 662, loss:1.1309808201076521e-08\n","Finished epoch 663, loss:1.1309808201076521e-08\n","Finished epoch 664, loss:1.114655390210828e-08\n","Finished epoch 665, loss:1.0654972015800013e-08\n","Finished epoch 666, loss:1.0543104167481943e-08\n","Finished epoch 667, loss:1.0543104167481943e-08\n","Finished epoch 668, loss:1.0465683430993522e-08\n","Finished epoch 669, loss:1.0133604178008682e-08\n","Finished epoch 670, loss:9.86189263585402e-09\n","Finished epoch 671, loss:9.753662766343041e-09\n","Finished epoch 672, loss:9.679311574473104e-09\n","Finished epoch 673, loss:9.552550750413502e-09\n","Finished epoch 674, loss:9.123837685365288e-09\n","Finished epoch 675, loss:9.095415975934884e-09\n","Finished epoch 676, loss:8.971383635980601e-09\n","Finished epoch 677, loss:8.971383635980601e-09\n","Finished epoch 678, loss:8.739576173866226e-09\n","Finished epoch 679, loss:8.723546329747478e-09\n","Finished epoch 680, loss:8.825409736346046e-09\n","Finished epoch 681, loss:8.51686365876958e-09\n","Finished epoch 682, loss:8.397492479161883e-09\n","Finished epoch 683, loss:8.264137818514428e-09\n","Finished epoch 684, loss:8.195243594855128e-09\n","Finished epoch 685, loss:8.279599228444567e-09\n","Finished epoch 686, loss:7.879989993853087e-09\n","Finished epoch 687, loss:7.913868671494129e-09\n","Finished epoch 688, loss:7.615554409312608e-09\n","Finished epoch 689, loss:7.764711540403368e-09\n","Finished epoch 690, loss:7.694680448366853e-09\n","Finished epoch 691, loss:7.2906374271042296e-09\n","Finished epoch 692, loss:7.487315656362625e-09\n","Finished epoch 693, loss:7.683766511945578e-09\n","Finished epoch 694, loss:7.371127708211134e-09\n","Finished epoch 695, loss:7.101689902810904e-09\n","Finished epoch 696, loss:7.196959472821618e-09\n","Finished epoch 697, loss:7.231975018839876e-09\n","Finished epoch 698, loss:7.090093845363299e-09\n","Finished epoch 699, loss:7.090093845363299e-09\n","Finished epoch 700, loss:6.835321642029157e-09\n","Finished epoch 701, loss:6.793598572585324e-09\n","Finished epoch 702, loss:7.0019865461290465e-09\n","Finished epoch 703, loss:7.0529182494283305e-09\n","Finished epoch 704, loss:6.911037075951754e-09\n","Finished epoch 705, loss:6.890232384648698e-09\n","Finished epoch 706, loss:6.82850043176586e-09\n","Finished epoch 707, loss:6.486871484412404e-09\n","Finished epoch 708, loss:6.64910260184115e-09\n","Finished epoch 709, loss:6.5072214283645735e-09\n","Finished epoch 710, loss:6.69548683163157e-09\n","Finished epoch 711, loss:6.654900630564953e-09\n","Finished epoch 712, loss:6.4728880033726455e-09\n","Finished epoch 713, loss:6.338282787510252e-09\n","Finished epoch 714, loss:6.318387590908969e-09\n","Finished epoch 715, loss:6.294854415500595e-09\n","Finished epoch 716, loss:6.274959218899312e-09\n","Finished epoch 717, loss:6.2789382582195685e-09\n","Finished epoch 718, loss:6.19253626155114e-09\n","Finished epoch 719, loss:6.307587341325416e-09\n","Finished epoch 720, loss:6.215955750121793e-09\n","Finished epoch 721, loss:5.995858032292745e-09\n","Finished epoch 722, loss:6.0154121683808626e-09\n","Finished epoch 723, loss:5.995858032292745e-09\n","Finished epoch 724, loss:5.918778356317489e-09\n","Finished epoch 725, loss:5.8958136150977225e-09\n","Finished epoch 726, loss:5.622055709864071e-09\n","Finished epoch 727, loss:5.622055709864071e-09\n","Finished epoch 728, loss:5.823395099469053e-09\n","Finished epoch 729, loss:5.80702419483714e-09\n","Finished epoch 730, loss:5.81611914185487e-09\n","Finished epoch 731, loss:5.48267564681737e-09\n","Finished epoch 732, loss:5.651159540320805e-09\n","Finished epoch 733, loss:5.48267564681737e-09\n","Finished epoch 734, loss:5.725965479541628e-09\n","Finished epoch 735, loss:5.50518564068625e-09\n","Finished epoch 736, loss:5.4706248420188786e-09\n","Finished epoch 737, loss:5.433676619759353e-09\n","Finished epoch 738, loss:5.433676619759353e-09\n","Finished epoch 739, loss:5.306347361511143e-09\n","Finished epoch 740, loss:5.433676619759353e-09\n","Finished epoch 741, loss:5.513712153515371e-09\n","Finished epoch 742, loss:5.038842232352181e-09\n","Finished epoch 743, loss:5.035545314058254e-09\n","Finished epoch 744, loss:5.074426212559047e-09\n","Finished epoch 745, loss:5.02122077250533e-09\n","Finished epoch 746, loss:5.1766306796707795e-09\n","Finished epoch 747, loss:5.1766306796707795e-09\n","Finished epoch 748, loss:5.137749781169987e-09\n","Finished epoch 749, loss:4.982339874004538e-09\n","Finished epoch 750, loss:4.879908033217362e-09\n","Finished epoch 751, loss:4.9474380148240016e-09\n","Finished epoch 752, loss:4.982339874004538e-09\n","Finished epoch 753, loss:4.750987159241049e-09\n","Finished epoch 754, loss:4.655603902392613e-09\n","Finished epoch 755, loss:4.7165400474113994e-09\n","Finished epoch 756, loss:4.699487021753157e-09\n","Finished epoch 757, loss:4.785775331583864e-09\n","Finished epoch 758, loss:4.549193022285181e-09\n","Finished epoch 759, loss:4.495191774367413e-09\n","Finished epoch 760, loss:4.731546709990653e-09\n","Finished epoch 761, loss:4.6152450750014395e-09\n","Finished epoch 762, loss:4.731546709990653e-09\n","Finished epoch 763, loss:4.652306984098686e-09\n","Finished epoch 764, loss:4.7111967660384835e-09\n","Finished epoch 765, loss:4.461654157239536e-09\n","Finished epoch 766, loss:4.44505587893218e-09\n","Finished epoch 767, loss:4.391964125716186e-09\n","Finished epoch 768, loss:4.303743139644212e-09\n","Finished epoch 769, loss:4.2874859218500205e-09\n","Finished epoch 770, loss:4.2791867826963426e-09\n","Finished epoch 771, loss:4.1909657966243685e-09\n","Finished epoch 772, loss:4.384119733913394e-09\n","Finished epoch 773, loss:4.348876814219693e-09\n","Finished epoch 774, loss:4.220069627081102e-09\n","Finished epoch 775, loss:4.123322128180007e-09\n","Finished epoch 776, loss:4.123322128180007e-09\n","Finished epoch 777, loss:4.072504111718445e-09\n","Finished epoch 778, loss:4.075573656336928e-09\n","Finished epoch 779, loss:3.990763275396603e-09\n","Finished epoch 780, loss:3.885261889990943e-09\n","Finished epoch 781, loss:4.079780069332628e-09\n","Finished epoch 782, loss:3.998039233010786e-09\n","Finished epoch 783, loss:3.869686793223082e-09\n","Finished epoch 784, loss:3.869686793223082e-09\n","Finished epoch 785, loss:3.73030673017638e-09\n","Finished epoch 786, loss:3.804998982559482e-09\n","Finished epoch 787, loss:3.8203467056519e-09\n","Finished epoch 788, loss:3.706773554768006e-09\n","Finished epoch 789, loss:3.4878127053161734e-09\n","Finished epoch 790, loss:3.684263560899126e-09\n","Finished epoch 791, loss:3.684263560899126e-09\n","Finished epoch 792, loss:3.639243573161366e-09\n","Finished epoch 793, loss:3.639243573161366e-09\n","Finished epoch 794, loss:3.459845743236656e-09\n","Finished epoch 795, loss:3.613777721511724e-09\n","Finished epoch 796, loss:3.681876137306972e-09\n","Finished epoch 797, loss:3.54033602434356e-09\n","Finished epoch 798, loss:3.5082763361060643e-09\n","Finished epoch 799, loss:3.6018406035509543e-09\n","Finished epoch 800, loss:3.5697809153134585e-09\n","Finished epoch 801, loss:3.5697809153134585e-09\n","Finished epoch 802, loss:3.4427927175784134e-09\n","Finished epoch 803, loss:3.4285818628632114e-09\n","Finished epoch 804, loss:3.3056863912861445e-09\n","Finished epoch 805, loss:3.2888607393033453e-09\n","Finished epoch 806, loss:3.148002747366263e-09\n","Finished epoch 807, loss:3.190635311511869e-09\n","Finished epoch 808, loss:3.1763107699589455e-09\n","Finished epoch 809, loss:3.1239011377692805e-09\n","Finished epoch 810, loss:3.001801474056265e-09\n","Finished epoch 811, loss:2.998504555762338e-09\n","Finished epoch 812, loss:2.998504555762338e-09\n","Finished epoch 813, loss:3.059213327105681e-09\n","Finished epoch 814, loss:3.187679453731107e-09\n","Finished epoch 815, loss:3.1602809258401976e-09\n","Finished epoch 816, loss:3.018286065525899e-09\n","Finished epoch 817, loss:3.0048710186747485e-09\n","Finished epoch 818, loss:3.059213327105681e-09\n","Finished epoch 819, loss:3.0294273756226175e-09\n","Finished epoch 820, loss:3.0294273756226175e-09\n","Finished epoch 821, loss:3.018286065525899e-09\n","Finished epoch 822, loss:2.961783707178256e-09\n","Finished epoch 823, loss:2.6699495947468677e-09\n","Finished epoch 824, loss:2.897550643865543e-09\n","Finished epoch 825, loss:2.8576465638252557e-09\n","Finished epoch 826, loss:2.870834237000963e-09\n","Finished epoch 827, loss:2.8576465638252557e-09\n","Finished epoch 828, loss:2.766697093647963e-09\n","Finished epoch 829, loss:2.7608990649241605e-09\n","Finished epoch 830, loss:2.7579432071433985e-09\n","Finished epoch 831, loss:2.7842048666570918e-09\n","Finished epoch 832, loss:2.7449829076431342e-09\n","Finished epoch 833, loss:2.7734046170735382e-09\n","Finished epoch 834, loss:2.7734046170735382e-09\n","Finished epoch 835, loss:2.7194033691557706e-09\n","Finished epoch 836, loss:2.7194033691557706e-09\n","Finished epoch 837, loss:2.691436407076253e-09\n","Finished epoch 838, loss:2.7194033691557706e-09\n","Finished epoch 839, loss:2.7067841301686713e-09\n","Finished epoch 840, loss:2.7067841301686713e-09\n","Finished epoch 841, loss:2.7697666382664465e-09\n","Finished epoch 842, loss:2.427341883048939e-09\n","Finished epoch 843, loss:2.562970280450827e-09\n","Finished epoch 844, loss:2.575362145762483e-09\n","Finished epoch 845, loss:2.3436683704858297e-09\n","Finished epoch 846, loss:2.3711805852144607e-09\n","Finished epoch 847, loss:2.350944328100013e-09\n","Finished epoch 848, loss:2.3496937728850753e-09\n","Finished epoch 849, loss:2.388233610872703e-09\n","Finished epoch 850, loss:2.388233610872703e-09\n","Finished epoch 851, loss:2.4002844156711944e-09\n","Finished epoch 852, loss:2.3238868607222685e-09\n","Finished epoch 853, loss:2.361630890845845e-09\n","Finished epoch 854, loss:2.300012624800729e-09\n","Finished epoch 855, loss:2.2424870849135914e-09\n","Finished epoch 856, loss:2.228048856522946e-09\n","Finished epoch 857, loss:2.2163391122376197e-09\n","Finished epoch 858, loss:2.2884165673531243e-09\n","Finished epoch 859, loss:2.274319399475644e-09\n","Finished epoch 860, loss:2.251240971418156e-09\n","Finished epoch 861, loss:2.068546223199519e-09\n","Finished epoch 862, loss:2.003403665185033e-09\n","Finished epoch 863, loss:2.029779011536448e-09\n","Finished epoch 864, loss:2.079801220133959e-09\n","Finished epoch 865, loss:1.992148668250593e-09\n","Finished epoch 866, loss:2.079801220133959e-09\n","Finished epoch 867, loss:2.0354633534225286e-09\n","Finished epoch 868, loss:2.0618386997739435e-09\n","Finished epoch 869, loss:1.916319547490275e-09\n","Finished epoch 870, loss:1.9963550812462927e-09\n","Finished epoch 871, loss:1.9055192979067215e-09\n","Finished epoch 872, loss:1.9090435898760916e-09\n","Finished epoch 873, loss:2.040351887444558e-09\n","Finished epoch 874, loss:1.942922267517133e-09\n","Finished epoch 875, loss:1.942922267517133e-09\n","Finished epoch 876, loss:1.915751113301667e-09\n","Finished epoch 877, loss:1.836056640058814e-09\n","Finished epoch 878, loss:1.9051782373935566e-09\n","Finished epoch 879, loss:1.836056640058814e-09\n","Finished epoch 880, loss:1.8255974509884254e-09\n","Finished epoch 881, loss:1.894719048323168e-09\n","Finished epoch 882, loss:1.8152519487557583e-09\n","Finished epoch 883, loss:1.7702319610179984e-09\n","Finished epoch 884, loss:1.70281566624908e-09\n","Finished epoch 885, loss:1.794902004803589e-09\n","Finished epoch 886, loss:1.6986092532533803e-09\n","Finished epoch 887, loss:1.692470164016413e-09\n","Finished epoch 888, loss:1.8305996718481765e-09\n","Finished epoch 889, loss:1.7187318235301063e-09\n","Finished epoch 890, loss:1.6496102261953638e-09\n","Finished epoch 891, loss:1.6496102261953638e-09\n","Finished epoch 892, loss:1.629715029594081e-09\n","Finished epoch 893, loss:1.5831034261282184e-09\n","Finished epoch 894, loss:1.7160033394247876e-09\n","Finished epoch 895, loss:1.6624568388579064e-09\n","Finished epoch 896, loss:1.7160033394247876e-09\n","Finished epoch 897, loss:1.6823520354591892e-09\n","Finished epoch 898, loss:1.6624568388579064e-09\n","Finished epoch 899, loss:1.5819665577510023e-09\n","Finished epoch 900, loss:1.5383108120659017e-09\n","Finished epoch 901, loss:1.5383108120659017e-09\n","Finished epoch 902, loss:1.4480434629149386e-09\n","Finished epoch 903, loss:1.404956151418446e-09\n","Finished epoch 904, loss:1.457365783608111e-09\n","Finished epoch 905, loss:1.4480434629149386e-09\n","Finished epoch 906, loss:1.4668017911390052e-09\n","Finished epoch 907, loss:1.4388348290594877e-09\n","Finished epoch 908, loss:1.397907567479706e-09\n","Finished epoch 909, loss:1.4051835250938893e-09\n","Finished epoch 910, loss:1.4071162013351568e-09\n","Finished epoch 911, loss:1.4071162013351568e-09\n","Finished epoch 912, loss:1.4071162013351568e-09\n","Finished epoch 913, loss:1.3622099004351185e-09\n","Finished epoch 914, loss:1.3269669807414175e-09\n","Finished epoch 915, loss:1.3622099004351185e-09\n","Finished epoch 916, loss:1.2982042107978486e-09\n","Finished epoch 917, loss:1.3091181472191238e-09\n","Finished epoch 918, loss:1.2805827509509982e-09\n","Finished epoch 919, loss:1.2719425512841553e-09\n","Finished epoch 920, loss:1.2831975482185953e-09\n","Finished epoch 921, loss:1.2526157888714806e-09\n","Finished epoch 922, loss:1.1276739542154246e-09\n","Finished epoch 923, loss:1.201570398734475e-09\n","Finished epoch 924, loss:1.1470007166280993e-09\n","Finished epoch 925, loss:1.1276739542154246e-09\n","Finished epoch 926, loss:1.1470007166280993e-09\n","Finished epoch 927, loss:1.1276739542154246e-09\n","Finished epoch 928, loss:1.0867466926356428e-09\n","Finished epoch 929, loss:1.1842899994007894e-09\n","Finished epoch 930, loss:1.1224443596802303e-09\n","Finished epoch 931, loss:1.1413163747420185e-09\n","Finished epoch 932, loss:1.1040270919693285e-09\n","Finished epoch 933, loss:1.1040270919693285e-09\n","Finished epoch 934, loss:1.0678746775738546e-09\n","Finished epoch 935, loss:1.1658727316898876e-09\n","Finished epoch 936, loss:1.142680616794678e-09\n","Finished epoch 937, loss:1.142680616794678e-09\n","Finished epoch 938, loss:9.94887727756577e-10\n","Finished epoch 939, loss:1.1639400554486201e-09\n","Finished epoch 940, loss:1.1479102113298723e-09\n","Finished epoch 941, loss:9.93409798866196e-10\n","Finished epoch 942, loss:1.0552554385867552e-09\n","Finished epoch 943, loss:9.53733092501352e-10\n","Finished epoch 944, loss:9.116689625443541e-10\n","Finished epoch 945, loss:9.042793180924491e-10\n","Finished epoch 946, loss:9.042793180924491e-10\n","Finished epoch 947, loss:8.898410897018039e-10\n","Finished epoch 948, loss:8.898410897018039e-10\n","Finished epoch 949, loss:8.732428113944479e-10\n","Finished epoch 950, loss:8.189005029635155e-10\n","Finished epoch 951, loss:8.876810397850932e-10\n","Finished epoch 952, loss:8.242437843364314e-10\n","Finished epoch 953, loss:8.189005029635155e-10\n","Finished epoch 954, loss:7.87068188401463e-10\n","Finished epoch 955, loss:8.362945891349227e-10\n","Finished epoch 956, loss:8.457305966658168e-10\n","Finished epoch 957, loss:8.206058055293397e-10\n","Finished epoch 958, loss:8.431157993982197e-10\n","Finished epoch 959, loss:8.206058055293397e-10\n","Finished epoch 960, loss:8.206058055293397e-10\n","Finished epoch 961, loss:7.193108331193798e-10\n","Finished epoch 962, loss:8.618741276222863e-10\n","Finished epoch 963, loss:8.211742397179478e-10\n","Finished epoch 964, loss:8.553939778721542e-10\n","Finished epoch 965, loss:6.662190799033851e-10\n","Finished epoch 966, loss:6.326814627755084e-10\n","Finished epoch 967, loss:7.193108331193798e-10\n","Finished epoch 968, loss:6.092619742048555e-10\n","Finished epoch 969, loss:6.559872645084397e-10\n","Finished epoch 970, loss:7.265867907335632e-10\n","Finished epoch 971, loss:7.071463414831669e-10\n","Finished epoch 972, loss:6.987335154917673e-10\n","Finished epoch 973, loss:7.535305712735862e-10\n","Finished epoch 974, loss:6.708802402499714e-10\n","Finished epoch 975, loss:6.587157486137585e-10\n","Finished epoch 976, loss:6.114220241215662e-10\n","Finished epoch 977, loss:6.114220241215662e-10\n","Finished epoch 978, loss:6.114220241215662e-10\n","Finished epoch 979, loss:6.092619742048555e-10\n","Finished epoch 980, loss:6.565556986970478e-10\n","Finished epoch 981, loss:6.565556986970478e-10\n","Finished epoch 982, loss:6.565556986970478e-10\n","Finished epoch 983, loss:6.565556986970478e-10\n","Finished epoch 984, loss:6.504166094600805e-10\n","Finished epoch 985, loss:6.726992296535172e-10\n","Finished epoch 986, loss:6.646274641752825e-10\n","Finished epoch 987, loss:5.741327413488762e-10\n","Finished epoch 988, loss:5.911857670071186e-10\n","Finished epoch 989, loss:6.670148877674364e-10\n","Finished epoch 990, loss:5.868656671736971e-10\n","Finished epoch 991, loss:5.068301334176795e-10\n","Finished epoch 992, loss:5.068301334176795e-10\n","Finished epoch 993, loss:5.639009259539307e-10\n","Finished epoch 994, loss:5.581028972301283e-10\n","Finished epoch 995, loss:5.581028972301283e-10\n","Finished epoch 996, loss:5.180851303521194e-10\n","Finished epoch 997, loss:5.180851303521194e-10\n","Finished epoch 998, loss:5.180851303521194e-10\n","Finished epoch 999, loss:5.180851303521194e-10\n"]}]},{"cell_type":"code","source":["# Compute accuracy (no_grad is optional)\n","with torch.no_grad():\n","    y_pred = model(Xtensor)\n","\n"," # We will estimate the error as a MSE function\n"," # between predictions and targets\n","error = torch.sum((y_pred - ytensor)**2)\n","print(f\"Error {error}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"STjoZ8x36WlS","executionInfo":{"status":"ok","timestamp":1695681254374,"user_tz":300,"elapsed":218,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"32603152-b1a2-4ac6-a3fe-cdbae715307c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Error 7.871867069297878e-08\n"]}]},{"cell_type":"markdown","source":["Once the model is trained, we can visualize the loss function during each epoch to see how the model is improving its learning. The variable `history` stores the information of the loss during the training process."],"metadata":{"id":"CBUNzTz4THzI"}},{"cell_type":"code","source":["plt.figure()\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss Magnitude')\n","plt.plot(history)\n","#plt.yscale('log')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"id":"f-159WqVE999","executionInfo":{"status":"ok","timestamp":1695681271106,"user_tz":300,"elapsed":254,"user":{"displayName":"Eduard Alexis Larranaga","userId":"04402438389940282602"}},"outputId":"0dba5dd0-d0b4-47b3-d0a3-83cb32093c25"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAkQAAAGwCAYAAABIC3rIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNOklEQVR4nO3deVxU9f4/8NcMMMM6wyYMJCiKoSjupZPL1eSKSotL96aRWlr+MPTmkpk3M2/L1avfMsvSlpvYvZppV800JcQtFZdI3EpMU9FkQEVmAGFY5vP7Azk1uTEwwxng9Xw85iFzzocz73N85Lz6nM/ncxRCCAEiIiKiJkwpdwFEREREcmMgIiIioiaPgYiIiIiaPAYiIiIiavIYiIiIiKjJYyAiIiKiJo+BiIiIiJo8V7kLaAgsFgsuXboEHx8fKBQKucshIiKiGhBCoLCwEKGhoVAq79wHxEBUA5cuXUJYWJjcZRAREVEtXLhwAc2bN79jGwaiGvDx8QFQdUE1Go3M1RAREVFNmEwmhIWFSd/jd8JAVAPVt8k0Gg0DERERUQNTk+EuHFRNRERETR4DERERETV5DERERETU5MkaiJYuXYqOHTtKY3P0ej22bNki7e/Xrx8UCoXVKzEx0eoY2dnZiI+Ph6enJ4KCgjBjxgxUVFRYtdm5cye6du0KtVqNyMhIJCcn18fpERERUQMh66Dq5s2bY/78+WjTpg2EEFixYgUeffRRHD58GO3btwcAPPvss3jttdek3/H09JR+rqysRHx8PHQ6Hfbt24ecnByMGTMGbm5u+Oc//wkAOHv2LOLj45GYmIiVK1ciLS0NzzzzDEJCQhAXF1e/J0xEREROSSGEEHIX8Xv+/v5YuHAhxo8fj379+qFz58545513btl2y5YteOihh3Dp0iUEBwcDAJYtW4aZM2fi8uXLUKlUmDlzJjZv3ozjx49Lvzdy5EgUFBRg69attzyu2WyG2WyW3ldP2zMajZxlRkRE1ECYTCZotdoafX87zRiiyspKrF69GsXFxdDr9dL2lStXIjAwEB06dMCsWbNw/fp1aV96ejpiYmKkMAQAcXFxMJlMOHHihNQmNjbW6rPi4uKQnp5+21rmzZsHrVYrvbgoIxERUeMm+zpEx44dg16vR2lpKby9vbF+/XpER0cDAJ544gm0aNECoaGhOHr0KGbOnImsrCysW7cOAGAwGKzCEADpvcFguGMbk8mEkpISeHh43FTTrFmzMG3aNOl9dQ8RERERNU6yB6KoqChkZmbCaDTiyy+/xNixY7Fr1y5ER0djwoQJUruYmBiEhIRgwIABOHPmDFq3bu2wmtRqNdRqtcOOT0RERM5F9ltmKpUKkZGR6NatG+bNm4dOnTph8eLFt2zbo0cPAMDp06cBADqdDrm5uVZtqt/rdLo7ttFoNLfsHSIiIqKmR/ZA9EcWi8VqQPPvZWZmAgBCQkIAAHq9HseOHUNeXp7UJjU1FRqNRrrtptfrkZaWZnWc1NRUq3FKRERE1LTJests1qxZGDx4MMLDw1FYWIhVq1Zh586dSElJwZkzZ7Bq1SoMGTIEAQEBOHr0KKZOnYq+ffuiY8eOAICBAwciOjoao0ePxoIFC2AwGDB79mwkJSVJt7wSExOxZMkSvPjiixg3bhy2b9+ONWvWYPPmzXKeOhERETkRWQNRXl4exowZg5ycHGi1WnTs2BEpKSn485//jAsXLmDbtm145513UFxcjLCwMIwYMQKzZ8+Wft/FxQWbNm3CxIkTodfr4eXlhbFjx1qtWxQREYHNmzdj6tSpWLx4MZo3b45PPvnEadYgKrhehrxCM+4NvvuTeImIiMgxnG4dImdkyzoGtvg5txB/XrQbPmpXHJ07sEZP4yUiIqKaaZDrEDVFYf5Vq24Xmitw7Xq5zNUQERE1XQxEMnJ3c0Gwpmqs0/mrxTJXQ0RE1HQxEMmsRYAXACA7//pdWhIREZGjMBDJrMWN22bnrzIQERERyYWBSGYtAhiIiIiI5MZAJLNw6ZYZxxARERHJhYFIZrxlRkREJD8GIplV3zLLKzSjpKxS5mqIiIiaJgYimfl6qqBxr1ownDPNiIiI5MFA5ASqp95zLSIiIiJ5MBA5Ac40IyIikhcDkROICKzqITrLHiIiIiJZMBA5gepbZueuMBARERHJgYHICUQEVt0yYyAiIiKSBwORE2h5o4fokrEUpeWcek9ERFTfGIicgL+XCj43pt5zYDUREVH9YyByAgqF4reB1bxtRkREVO8YiJxE9W2zc5xpRkREVO8YiJxES2ktIgYiIiKi+sZA5CRa8pYZERGRbBiInER1IDp3hYOqiYiI6hsDkZOIuDGGyGAq5VPviYiI6hkDkZPw8/rtqffn83nbjIiIqD4xEDmRMP+qgdW/XiuRuRIiIqKmhYHIidzj6wEA+LWAgYiIiKg+MRA5keZ+VT1EF9lDREREVK8YiJzIPX43eogYiIiIiOoVA5ETaX4jEF28xqn3RERE9YmByIlwDBEREZE8GIicSNiNMURXisq4FhEREVE9YiByIhoPV3irq9YiYi8RERFR/WEgciIKhYLjiIiIiGTAQORkOI6IiIio/jEQORlOvSciIqp/DERORqd1B1D1kFciIiKqHwxETkanqQpEuQxERERE9YaByMlUByKDkYGIiIiovjAQOZlgbXUPkVnmSoiIiJoOWQPR0qVL0bFjR2g0Gmg0Guj1emzZskXaX1paiqSkJAQEBMDb2xsjRoxAbm6u1TGys7MRHx8PT09PBAUFYcaMGaioqLBqs3PnTnTt2hVqtRqRkZFITk6uj9OrleoeoiJzBYrMFXdpTURERPYgayBq3rw55s+fj4yMDHz//fd48MEH8eijj+LEiRMAgKlTp+Lrr7/G2rVrsWvXLly6dAnDhw+Xfr+yshLx8fEoKyvDvn37sGLFCiQnJ2POnDlSm7NnzyI+Ph79+/dHZmYmpkyZgmeeeQYpKSn1fr414aV2hc+NxRl524yIiKh+KIQQQu4ifs/f3x8LFy7EY489hmbNmmHVqlV47LHHAAAnT55Eu3btkJ6ejp49e2LLli146KGHcOnSJQQHBwMAli1bhpkzZ+Ly5ctQqVSYOXMmNm/ejOPHj0ufMXLkSBQUFGDr1q23rMFsNsNs/u2WlclkQlhYGIxGIzQajQPPvkrs27twOq8IK5/pgV6RgQ7/PCIiosbIZDJBq9XW6PvbacYQVVZWYvXq1SguLoZer0dGRgbKy8sRGxsrtWnbti3Cw8ORnp4OAEhPT0dMTIwUhgAgLi4OJpNJ6mVKT0+3OkZ1m+pj3Mq8efOg1WqlV1hYmD1P9a6qb5vlsIeIiIioXsgeiI4dOwZvb2+o1WokJiZi/fr1iI6OhsFggEqlgq+vr1X74OBgGAwGAIDBYLAKQ9X7q/fdqY3JZEJJya0XP5w1axaMRqP0unDhgj1OtcaCOfWeiIioXrnKXUBUVBQyMzNhNBrx5ZdfYuzYsdi1a5esNanVaqjVatk+X6et+myOISIiIqofsgcilUqFyMhIAEC3bt1w6NAhLF68GI8//jjKyspQUFBg1UuUm5sLnU4HANDpdDh48KDV8apnof2+zR9npuXm5kKj0cDDw8NRp1Un0lpE7CEiIiKqF7LfMvsji8UCs9mMbt26wc3NDWlpadK+rKwsZGdnQ6/XAwD0ej2OHTuGvLw8qU1qaio0Gg2io6OlNr8/RnWb6mM4I94yIyIiql+y9hDNmjULgwcPRnh4OAoLC7Fq1Srs3LkTKSkp0Gq1GD9+PKZNmwZ/f39oNBpMnjwZer0ePXv2BAAMHDgQ0dHRGD16NBYsWACDwYDZs2cjKSlJuuWVmJiIJUuW4MUXX8S4ceOwfft2rFmzBps3b5bz1O+o+nlmeVyckYiIqF7IGojy8vIwZswY5OTkQKvVomPHjkhJScGf//xnAMCiRYugVCoxYsQImM1mxMXF4YMPPpB+38XFBZs2bcLEiROh1+vh5eWFsWPH4rXXXpPaREREYPPmzZg6dSoWL16M5s2b45NPPkFcXFy9n29NBXpXhbmrxWZYLAJKpULmioiIiBo3p1uHyBnZso6BPZgrKhE1u2qNpMOv/Bl+XiqHfyYREVFj0yDXIaLfqF1doPVwAwBcKeJtMyIiIkdjIHJSgd5VvUKXCxmIiIiIHI2ByEk186kaR3SZPUREREQOx0DkpKoHVrOHiIiIyPEYiJxUdSC6UlQmcyVERESNHwORk6q+ZcZB1URERI7HQOSkmvGWGRERUb1hIHJS7CEiIiKqPwxEToqDqomIiOoPA5GTCvSpWofoanEZLBYuJk5ERORIDEROKsCrqoeo0iJQUFIuczVERESNGwORk1K5KuHrWfX4Dt42IyIiciwGIif221pEDERERESOxEDkxDj1noiIqH4wEDmxQE69JyIiqhcMRE5M6iFiICIiInIoBiInVj31nrfMiIiIHIuByIkF3ph6n1/MB7wSERE5EgORE/P3quohYiAiIiJyLAYiJ+Z3IxBdLWIgIiIiciQGIicWcCMQXbvOQERERORIDEROzN+7KhBdL6tEaXmlzNUQERE1XgxETsxH7Qo3FwWAqoe8EhERkWMwEDkxhUIBP88bt80YiIiIiByGgcjJVc80Yw8RERGR4zAQObkA7+qp91yckYiIyFEYiJxc9S2z/OJymSshIiJqvBiInFyAF3uIiIiIHI2ByMn58/EdREREDsdA5OT8vdwAMBARERE5EgORk2MPERERkeMxEDk5TrsnIiJyPAYiJ1cdiLgwIxERkeMwEDm56kBUUFKOSouQuRoiIqLGiYHIyfl5Vg2qFoJPvSciInIUBiIn5+qihNajKhTxthkREZFjMBA1AAEcWE1ERORQDEQNgL+0WjUDERERkSPIGojmzZuH++67Dz4+PggKCsLQoUORlZVl1aZfv35QKBRWr8TERKs22dnZiI+Ph6enJ4KCgjBjxgxUVFRYtdm5cye6du0KtVqNyMhIJCcnO/r07MaPgYiIiMihZA1Eu3btQlJSEvbv34/U1FSUl5dj4MCBKC4utmr37LPPIicnR3otWLBA2ldZWYn4+HiUlZVh3759WLFiBZKTkzFnzhypzdmzZxEfH4/+/fsjMzMTU6ZMwTPPPIOUlJR6O9e6CGAgIiIicihXOT9869atVu+Tk5MRFBSEjIwM9O3bV9ru6ekJnU53y2N8++23+PHHH7Ft2zYEBwejc+fOeP311zFz5kzMnTsXKpUKy5YtQ0REBN566y0AQLt27bBnzx4sWrQIcXFxNx3TbDbDbP7tYaomk8kep1trvjeeeF9wnU+8JyIicgSnGkNkNBoBAP7+/lbbV65cicDAQHTo0AGzZs3C9evXpX3p6emIiYlBcHCwtC0uLg4mkwknTpyQ2sTGxlodMy4uDunp6besY968edBqtdIrLCzMLudXW743pt4XcNo9ERGRQ8jaQ/R7FosFU6ZMQa9evdChQwdp+xNPPIEWLVogNDQUR48excyZM5GVlYV169YBAAwGg1UYAiC9NxgMd2xjMplQUlICDw8Pq32zZs3CtGnTpPcmk0nWUFS9FhHXISIiInIMpwlESUlJOH78OPbs2WO1fcKECdLPMTExCAkJwYABA3DmzBm0bt3aIbWo1Wqo1WqHHLs2qm+ZXeMtMyIiIodwiltmkyZNwqZNm7Bjxw40b978jm179OgBADh9+jQAQKfTITc316pN9fvqcUe3a6PRaG7qHXJGftIYIvYQEREROYKsgUgIgUmTJmH9+vXYvn07IiIi7vo7mZmZAICQkBAAgF6vx7Fjx5CXlye1SU1NhUajQXR0tNQmLS3N6jipqanQ6/V2OhPH+u2WGXuIiIiIHEHWQJSUlIT//ve/WLVqFXx8fGAwGGAwGFBSUgIAOHPmDF5//XVkZGTg3Llz2LhxI8aMGYO+ffuiY8eOAICBAwciOjoao0ePxpEjR5CSkoLZs2cjKSlJuu2VmJiIX375BS+++CJOnjyJDz74AGvWrMHUqVNlO3dbVN8yM5XyAa9ERESOIGsgWrp0KYxGI/r164eQkBDp9cUXXwAAVCoVtm3bhoEDB6Jt27aYPn06RowYga+//lo6houLCzZt2gQXFxfo9Xo8+eSTGDNmDF577TWpTUREBDZv3ozU1FR06tQJb731Fj755JNbTrl3Rr6/e8CrsYS9RERERPamEEKwy+EuTCYTtFotjEYjNBqNLDXEvJqCQnMFtk//E1o185alBiIioobElu9vpxhUTXen5TgiIiIih2EgaiA404yIiMhxGIgaCF/2EBERETkMA1EDwR4iIiIix2EgaiD4+A4iIiLHYSBqIPj4DiIiIsdhIGog/PjEeyIiIodhIGog/LyqxxCxh4iIiMjeGIgaCN4yIyIichwGogbC14O3zIiIiByFgaiB8JN6iBiIiIiI7I2BqIHw9arqISott6C0vFLmaoiIiBoXBqIGwkftClelAgB7iYiIiOyNgaiBUCgUvz2+o5gDq4mIiOyJgagB8eXjO4iIiByCgagBkRZnLGEPERERkT0xEDUgvpxpRkRE5BAMRA3Ib2sRsYeIiIjInmoViM6cOYPZs2dj1KhRyMvLAwBs2bIFJ06csGtxZK368R3XitlDREREZE82B6Jdu3YhJiYGBw4cwLp161BUVAQAOHLkCF599VW7F0i/kWaZsYeIiIjIrmwORC+99BLeeOMNpKamQqVSSdsffPBB7N+/367FkTU/zjIjIiJyCJsD0bFjxzBs2LCbtgcFBeHKlSt2KYpujbPMiIiIHMPmQOTr64ucnJybth8+fBj33HOPXYqiW9N6cJYZERGRI9gciEaOHImZM2fCYDBAoVDAYrFg7969eOGFFzBmzBhH1Eg3+N14npmRY4iIiIjsyuZA9M9//hNt27ZFWFgYioqKEB0djb59++KBBx7A7NmzHVEj3eB7o4eooKQcQgiZqyEiImo8XG39BZVKhY8//hivvPIKjh8/jqKiInTp0gVt2rRxRH30O9WzzCotAoXmCmjc3WSuiIiIqHGwORBVCw8PR3h4uD1robtwd3OBu5sSpeUWFBSXMxARERHZSY0C0bRp02p8wLfffrvWxdDd+XmqkGMsRUFJGcLhKXc5REREjUKNAtHhw4et3v/www+oqKhAVFQUAODUqVNwcXFBt27d7F8hWdF6uCHHWMrFGYmIiOyoRoFox44d0s9vv/02fHx8sGLFCvj5+QEArl27hqeffhp9+vRxTJUk4eKMRERE9mfzLLO33noL8+bNk8IQAPj5+eGNN97AW2+9Zdfi6GbVU+/5gFciIiL7sTkQmUwmXL58+abtly9fRmFhoV2KoturXpyRgYiIiMh+bA5Ew4YNw9NPP41169bh4sWLuHjxIv73v/9h/PjxGD58uCNqpN/xkx7wyltmRERE9mLztPtly5bhhRdewBNPPIHy8qpeCldXV4wfPx4LFy60e4FkrXotIiOfZ0ZERGQ3NgciT09PfPDBB1i4cCHOnDkDAGjdujW8vLzsXhzdzNeTzzMjIiKyt1ovzOjl5YWOHTvasxaqAV8PDqomIiKyN5sDUf/+/aFQKG67f/v27XUqiO7Mz4vT7omIiOzN5kDUuXNnq/fl5eXIzMzE8ePHMXbsWHvVRbch9RBxDBEREZHd2DzLbNGiRVavJUuWYM+ePZgyZQrc3Gx7tta8efNw3333wcfHB0FBQRg6dCiysrKs2pSWliIpKQkBAQHw9vbGiBEjkJuba9UmOzsb8fHx8PT0RFBQEGbMmIGKigqrNjt37kTXrl2hVqsRGRmJ5ORkW0/dKVSPITKWlKPSwifeExER2YPNgeh2nnzySXz66ac2/c6uXbuQlJSE/fv3IzU1FeXl5Rg4cCCKi4ulNlOnTsXXX3+NtWvXYteuXbh06ZLV9P7KykrEx8ejrKwM+/btw4oVK5CcnIw5c+ZIbc6ePYv4+Hj0798fmZmZmDJlCp555hmkpKTU/cTrmfZGD5EQgIm9RERERPYh7OSzzz4TISEhdTpGXl6eACB27dolhBCioKBAuLm5ibVr10ptfvrpJwFApKenCyGE+Oabb4RSqRQGg0Fqs3TpUqHRaITZbBZCCPHiiy+K9u3bW33W448/LuLi4mpUl9FoFACE0Wis0/nZS/s5W0WLmZvEL5eL5C6FiIjIadny/W3zGKI/Lr4ohEBOTg6+//57vPLKK3UKZ0ajEQDg7+8PAMjIyEB5eTliY2OlNm3btkV4eDjS09PRs2dPpKenIyYmBsHBwVKbuLg4TJw4ESdOnECXLl2Qnp5udYzqNlOmTLllHWazGWazWXpvMpnqdF72pvVwQ5G5AteulyECXO6AiIiormwORBqNxmqWmVKpRFRUFF577TUMHDiw1oVYLBZMmTIFvXr1QocOHQAABoMBKpUKvr6+Vm2Dg4NhMBikNr8PQ9X7q/fdqY3JZEJJSQk8PDys9s2bNw//+Mc/an0ujubn5YZfC0pg5NR7IiIiu7A5EDlqMHJSUhKOHz+OPXv2OOT4tpg1axamTZsmvTeZTAgLC5OxImu+HlyckYiIyJ5sHlTdqlUrXL169abtBQUFaNWqVa2KmDRpEjZt2oQdO3agefPm0nadToeysjIUFBRYtc/NzYVOp5Pa/HHWWfX7u7XRaDQ39Q4BgFqthkajsXo5k+rHd3BxRiIiIvuwORCdO3cOlZWVN203m8349ddfbTqWEAKTJk3C+vXrsX37dkRERFjt79atG9zc3JCWliZty8rKQnZ2NvR6PQBAr9fj2LFjyMvLk9qkpqZCo9EgOjpaavP7Y1S3qT5GQ/NbIGIPERERkT3U+JbZxo0bpZ9TUlKg1Wql95WVlUhLS0PLli1t+vCkpCSsWrUKX331FXx8fKQxP1qtFh4eHtBqtRg/fjymTZsGf39/aDQaTJ48GXq9Hj179gQADBw4ENHR0Rg9ejQWLFgAg8GA2bNnIykpCWq1GgCQmJiIJUuW4MUXX8S4ceOwfft2rFmzBps3b7apXmfhd2MtIi7OSEREZCc1nbqmUCiEQqEQSqVS+rn6pVKpxL333iu+/vprm6bDAbjla/ny5VKbkpIS8dxzzwk/Pz/h6ekphg0bJnJycqyOc+7cOTF48GDh4eEhAgMDxfTp00V5eblVmx07dojOnTsLlUolWrVqZfUZd+Ns0+4/3n1GtJi5SUxa9YPcpRARETktW76/FUIIm5Y7joiIwKFDhxAYGGjvbOa0TCYTtFotjEajU4wn+l/GRUxfewR92gTiP+N7yF0OERGRU7Ll+9vmWWZnz56tdWFkHxxUTUREZF81CkTvvvsuJkyYAHd3d7z77rt3bPu3v/3NLoXR7flKY4g4qJqIiMgeahSIFi1ahISEBLi7u2PRokW3badQKBiI6oHUQ1TMHiIiIiJ7qFEg+v1tMt4yk1/1LLNCcwXKKy1wc7HbM3qJiIiaJH6TNkAa999yrJFT74mIiOrM5kHVlZWVSE5ORlpaGvLy8mCxWKz2b9++3W7F0a25uiihcXeFqbQCBdfLEeitlrskIiKiBs3mQPT8888jOTkZ8fHx6NChg9WDXqn++HqqbgQiDqwmIiKqK5sD0erVq7FmzRoMGTLEEfVQDfl5uiE7n1PviYiI7MHmMUQqlQqRkZGOqIVsoPXkE++JiIjsxeZANH36dCxevBg2LnBNduZ3Y+o9B1UTERHVnc23zPbs2YMdO3Zgy5YtaN++Pdzc3Kz2r1u3zm7F0e35elRdd/YQERER1Z3NgcjX1xfDhg1zRC1kA2m1ao4hIiIiqjObA9Hy5csdUQfZiM8zIyIish8uzNhA+fF5ZkRERHZjcw9Rly5dbrn2kEKhgLu7OyIjI/HUU0+hf//+dimQbk17o4foGp9nRkREVGc29xANGjQIv/zyC7y8vNC/f3/0798f3t7eOHPmDO677z7k5OQgNjYWX331lSPqpRuqe4g4y4yIiKjubO4hunLlCqZPn45XXnnFavsbb7yB8+fP49tvv8Wrr76K119/HY8++qjdCiVrnGVGRERkPzb3EK1ZswajRo26afvIkSOxZs0aAMCoUaOQlZVV9+rotqp7iK6XVcJcUSlzNURERA2bzYHI3d0d+/btu2n7vn374O7uDgCwWCzSz+QYPu6uUN4YymXkTDMiIqI6sfmW2eTJk5GYmIiMjAzcd999AIBDhw7hk08+wd///ncAQEpKCjp37mzXQsmaUqmA1sMN166Xo6CkHEEaBlAiIqLasjkQzZ49GxEREViyZAn+85//AACioqLw8ccf44knngAAJCYmYuLEifatlG7i66nCtevluFbMcURERER1YXMgAoCEhAQkJCTcdr+Hh0etC6KakxZn5EwzIiKiOuHCjA1Y9UyzAs40IyIiqhObe4gqKyuxaNEirFmzBtnZ2Sgrs/4yzs/Pt1txdGd+fJ4ZERGRXdjcQ/SPf/wDb7/9Nh5//HEYjUZMmzYNw4cPh1KpxNy5cx1QIt2OtFo1AxEREVGd2ByIVq5ciY8//hjTp0+Hq6srRo0ahU8++QRz5szB/v37HVEj3cZvq1XzlhkREVFd2ByIDAYDYmJiAADe3t4wGo0AgIceegibN2+2b3V0R758nhkREZFd2ByImjdvjpycHABA69at8e233wKoWotIrVbbtzq6I98bPUR8fAcREVHd2ByIhg0bhrS0NABVizS+8soraNOmDcaMGYNx48bZvUC6vepZZnzAKxERUd3YPMts/vz50s+PP/44wsPDkZ6ejjZt2uDhhx+2a3F0Z37sISIiIrKLWi3M+Ht6vR56vd4etZCNpIUZOcuMiIioTmociHbv3l2jdn379q11MWSb6kBkrrCgpKwSHioXmSsiIiJqmGociPr16weFourx6kKIW7ZRKBSorKy0T2V0V95qV7gqFaiwCBSUlMFDxUemEBER1UaNA5Gfnx98fHzw1FNPYfTo0QgMDHRkXVQDCoUCvp5uuFJUhmvF5QjRMhARERHVRo1nmeXk5OBf//oX0tPTERMTg/Hjx2Pfvn3QaDTQarXSi+pX9dT7Ai7OSEREVGs1DkQqlQqPP/44UlJScPLkSXTs2BGTJk1CWFgYXn75ZVRUVDiyTrqN3x7wyoHVREREtVWrp92Hh4djzpw52LZtG+69917Mnz8fJpPJ3rVRDfjyAa9ERER1ZnMgMpvNWLVqFWJjY9GhQwcEBgZi8+bN8Pf3d0R9dBfS4zu4FhEREVGt1TgQHTx4EBMnToROp8PChQvxyCOP4MKFC1izZg0GDRpUqw/fvXs3Hn74YYSGhkKhUGDDhg1W+5966ikoFAqr1x8/Kz8/HwkJCdBoNPD19cX48eNRVFRk1ebo0aPo06cP3N3dERYWhgULFtSqXmfk58nVqomIiOqqxrPMevbsifDwcPztb39Dt27dAAB79uy5qd0jjzxS4w8vLi5Gp06dMG7cOAwfPvyWbQYNGoTly5dL7//4vLSEhATk5OQgNTUV5eXlePrppzFhwgSsWrUKAGAymTBw4EDExsZi2bJlOHbsGMaNGwdfX19MmDChxrU6K+l5ZsXsISIiIqotm1aqzs7Oxuuvv37b/bauQzR48GAMHjz4jm3UajV0Ot0t9/3000/YunUrDh06hO7duwMA3nvvPQwZMgT/93//h9DQUKxcuRJlZWX49NNPoVKp0L59e2RmZuLtt99uJIGo+pYZe4iIiIhqq8a3zCwWy11fjliUcefOnQgKCkJUVBQmTpyIq1evSvvS09Ph6+srhSEAiI2NhVKpxIEDB6Q2ffv2hUqlktrExcUhKysL165du+Vnms1mmEwmq5ezCvCqOq+rxWaZKyEiImq4ajXLrL4MGjQIn332GdLS0vCvf/0Lu3btwuDBg6XgZTAYEBQUZPU7rq6u8Pf3h8FgkNoEBwdbtal+X93mj+bNm2e1tlJYWJi9T81uAr2rbiFeLeItMyIiotqq88NdHWnkyJHSzzExMejYsSNat26NnTt3YsCAAQ773FmzZmHatGnSe5PJ5LShKOBGILpSxB4iIiKi2nLqHqI/atWqFQIDA3H69GkAgE6nQ15enlWbiooK5OfnS+OOdDodcnNzrdpUv7/d2CS1Wg2NRmP1claB3lW3zK6XVeJ6GRfHJCIiqo0GFYguXryIq1evIiQkBACg1+tRUFCAjIwMqc327dthsVjQo0cPqc3u3btRXv7boOPU1FRERUXBz8+vfk/AAbzVrlC5Vv018rYZERFR7cgaiIqKipCZmYnMzEwAwNmzZ5GZmYns7GwUFRVhxowZ2L9/P86dO4e0tDQ8+uijiIyMRFxcHACgXbt2GDRoEJ599lkcPHgQe/fuxaRJkzBy5EiEhoYCAJ544gmoVCqMHz8eJ06cwBdffIHFixdb3RJryBQKBZrxthkREVGd2ByILly4gIsXL0rvDx48iClTpuCjjz6y+cO///57dOnSBV26dAEATJs2DV26dMGcOXPg4uKCo0eP4pFHHsG9996L8ePHo1u3bvjuu++s1iJauXIl2rZtiwEDBmDIkCHo3bu3VS1arRbffvstzp49i27dumH69OmYM2dOo5hyXy3gxm0z9hARERHVjkIIIWz5hT59+mDChAkYPXo0DAYDoqKi0L59e/z888+YPHky5syZ46haZWMymaDVamE0Gp1yPNG45EPYfjIP84fHYOT94XKXQ0RE5BRs+f62uYfo+PHjuP/++wEAa9asQYcOHbBv3z6sXLkSycnJtSqY6ua3tYjYQ0RERFQbNgei8vJy6ZbVtm3bpEd1tG3bFjk5Ofatjmok0Kfq7+NyIccQERER1YbNgah9+/ZYtmwZvvvuO6SmpkoPW7106RICAgLsXiDdHXuIiIiI6sbmQPSvf/0LH374Ifr164dRo0ahU6dOAICNGzdKt9KofjW70UN0hT1EREREtWLzStX9+vXDlStXYDKZrNbxmTBhAjw9Pe1aHNVMgNeNx3fweWZERES1YnMPUUlJCcxmsxSGzp8/j3feeQdZWVk3PVeM6kf1tPsrnHZPRERUKzYHokcffRSfffYZAKCgoAA9evTAW2+9haFDh2Lp0qV2L5DurvoBr9eul6Gi0iJzNURERA2PzYHohx9+QJ8+fQAAX375JYKDg3H+/Hl89tlnePfdd+1eIN2dv5cKLkoFhGAvERERUW3YHIiuX78OHx8fAMC3336L4cOHQ6lUomfPnjh//rzdC6S7c1EqEHRjYLXBVCpzNURERA2PzYEoMjISGzZswIULF5CSkoKBAwcCAPLy8pxyFeemQqd1BwAYjCUyV0JERNTw2ByI5syZgxdeeAEtW7bE/fffD71eD6Cqt6j6mWRU/0KkQMQeIiIiIlvZPO3+scceQ+/evZGTkyOtQQQAAwYMwLBhw+xaHNVcsKYqEOXwlhkREZHNbA5EAKDT6aDT6aSn3jdv3pyLMsqsuocolz1ERERENrP5lpnFYsFrr70GrVaLFi1aoEWLFvD19cXrr78Oi4VTvuUi9RAxEBEREdnM5h6il19+Gf/+978xf/589OrVCwCwZ88ezJ07F6WlpXjzzTftXiTdXYjWAwBnmREREdWGzYFoxYoV+OSTT6Sn3ANAx44dcc899+C5555jIJLJ7wdVCyGgUChkroiIiKjhsPmWWX5+Ptq2bXvT9rZt2yI/P98uRZHtgjRV6xCZKywouF4uczVEREQNi82BqFOnTliyZMlN25csWWI164zql9rVBQFeVc80420zIiIi29h8y2zBggWIj4/Htm3bpDWI0tPTceHCBXzzzTd2L5BqTqd1x9XiMhiMpWgXwkUyiYiIasrmHqI//elPOHXqFIYNG4aCggIUFBRg+PDhyMrKkp5xRvKoHkd0iatVExER2aRW6xCFhobeNHj64sWLmDBhAj766CO7FEa2a+7nCQDIzr8ucyVEREQNi809RLdz9epV/Pvf/7bX4agWwv1vBKKrDERERES2sFsgIvm1CKgKROcZiIiIiGzCQNSIVAei7PzrEELIXA0REVHDwUDUiDT384RCARSZK5BfXCZ3OURERA1GjQdVDx8+/I77CwoK6loL1ZG7mwt0GnfkGEuRnX8dAd5quUsiIiJqEGociLRa7V33jxkzps4FUd20CPBEjrEUZy4Xo0u4n9zlEBERNQg1DkTLly93ZB1kJ1HBPtj/Sz5+zi2UuxQiIqIGg2OIGpk2wT4AgFMMRERERDXGQNTIROmqA1GRzJUQERE1HAxEjcy9QVWB6NeCEhSW8qn3RERENcFA1MhoPd2g01Q90+ykgbfNiIiIaoKBqBHqFFY1I/Bw9jWZKyEiImoYGIgaoerp9oezC+QthIiIqIFgIGqEuoT5AgB+yL7GR3gQERHVAANRIxTTXAtXpQK5JjMu5JfIXQ4REZHTYyBqhDxVrujaouq22c5TeTJXQ0RE5PwYiBqp/lFBAIDtJxmIiIiI7kbWQLR79248/PDDCA0NhUKhwIYNG6z2CyEwZ84chISEwMPDA7Gxsfj555+t2uTn5yMhIQEajQa+vr4YP348ioqsFyU8evQo+vTpA3d3d4SFhWHBggWOPjXZPdi2KhDtO3MVJq5HREREdEeyBqLi4mJ06tQJ77///i33L1iwAO+++y6WLVuGAwcOwMvLC3FxcSgtLZXaJCQk4MSJE0hNTcWmTZuwe/duTJgwQdpvMpkwcOBAtGjRAhkZGVi4cCHmzp2Ljz76yOHnJ6d7g73RJsgbZRUWbMy8JHc5REREzk04CQBi/fr10nuLxSJ0Op1YuHChtK2goECo1Wrx+eefCyGE+PHHHwUAcejQIanNli1bhEKhEL/++qsQQogPPvhA+Pn5CbPZLLWZOXOmiIqKqnFtRqNRABBGo7G2pyeLj3efES1mbhJDFu8WFotF7nKIiIjqlS3f3047hujs2bMwGAyIjY2Vtmm1WvTo0QPp6ekAgPT0dPj6+qJ79+5Sm9jYWCiVShw4cEBq07dvX6hUKqlNXFwcsrKycO3arRcuNJvNMJlMVq+GaHjX5vBwc8GJSyaOJSIiIroDpw1EBoMBABAcHGy1PTg4WNpnMBgQFBRktd/V1RX+/v5WbW51jN9/xh/NmzcPWq1WeoWFhdX9hGTg76XC2AdaAgDmbzkJc0WlvAURERE5KacNRHKaNWsWjEaj9Lpw4YLcJdVa4p9aIdBbhZ/zivB/KVlyl0NEROSUnDYQ6XQ6AEBubq7V9tzcXGmfTqdDXp71raCKigrk5+dbtbnVMX7/GX+kVquh0WisXg2Vr6cKbwyNAQB8/N1ZrDqQLXNFREREzsdpA1FERAR0Oh3S0tKkbSaTCQcOHIBerwcA6PV6FBQUICMjQ2qzfft2WCwW9OjRQ2qze/dulJf/NvU8NTUVUVFR8PPzq6ezkdegDjo8P6ANAODlDcfwWfo5eQsiIiJyMrIGoqKiImRmZiIzMxNA1UDqzMxMZGdnQ6FQYMqUKXjjjTewceNGHDt2DGPGjEFoaCiGDh0KAGjXrh0GDRqEZ599FgcPHsTevXsxadIkjBw5EqGhoQCAJ554AiqVCuPHj8eJEyfwxRdfYPHixZg2bZpMZy2PKbFtMEbfAkIAc746gVnrjqKkjGOKiIiIAEAhhHxP/9y5cyf69+9/0/axY8ciOTkZQgi8+uqr+Oijj1BQUIDevXvjgw8+wL333iu1zc/Px6RJk/D1119DqVRixIgRePfdd+Ht7S21OXr0KJKSknDo0CEEBgZi8uTJmDlzZo3rNJlM0Gq1MBqNDfr2mRAC7+84jbdST0EIoE2QN94Z2RntQ7Vyl0ZERGR3tnx/yxqIGorGEoiq7T19BVO+yMTlQjNclAo80zsCz8e2gafKVe7SiIiI7MaW72+nHUNEjtMrMhBbn++DITE6VFoEPtz9CwYu2o3tJ3Pv/stERESNEANRExXgrcYHCd3w77HdcY+vBy5eK8G45O8x9tODOJ1XdPcDEBERNSK8ZVYDje2W2R8VmyvwbtrP+HTvWZRXCrgqFRijb4nnY9tA6+Emd3lERES1wjFEdtbYA1G1s1eK8ebmH7Htp6q1nfy9VJg+8F6MvC8cLkqFzNURERHZhoHIzppKIKq269RlvL7pR+nWWbsQDeY8FA196wCZKyMiIqo5BiI7a2qBCADKKy347/7zWJR6CqbSCgBAXPtgvDwkGuEBnjJXR0REdHcMRHbWFANRtfziMryz7RRWHshGpUVA5aLE071bYlL/SPi4c3wRERE5LwYiO2vKgajaqdxCvL7pR3z38xUAQKC3Ci8MjMJfuodxfBERETklBiI7YyCqIoTA9pN5eHPzT/jlSjEAIDpEgzkPR6NnK44vIiIi58JAZGcMRNbKKiz4z/7zWLztt/FFg9rr8Pch7Ti+iIiInAYDkZ0xEN1afnEZFqWewsoD52ERgMpFiXG9I5DUvzXHFxERkewYiOyMgejOsgyFeGPz78cXqTEj7l481o3ji4iISD4MRHbGQHR31eOL3tj8E87eGF/UPlSDVx7i+CIiIpIHA5GdMRDVXFmFBZ+ln8PitJ9ReGN80eAOOswazPFFRERUvxiI7IyByHa3Gl80vk8EkvpHwlvtKnd5RETUBDAQ2RkDUe1lGarWL9pz+rfxRS/GReGxbs2h5PgiIiJyIAYiO2MgqhshBNJ+ysOb3/w2vqhruC9eH9oB7UO1MldHRESNFQORnTEQ2UdZhQUr9p3DO9tOobisEkoFMPaBlpj253s5TZ+IiOzOlu9vZT3VRASVqxLP9m2FtOn9EN8xBBYBLN97Dg++tQtfZf4KZnMiIpILAxHVO53WHe8/0RWfjbsfEYFeuFxoxvOrM/HExwdwOq9Q7vKIiKgJYiAi2fS9txm2TumD6X++F2pXJdJ/uYrBi7/Dgq0nUVpeKXd5RETUhDAQkazUri6YPKANUqf+CQ+2DUJ5pcAHO89g0Du7kX7mqtzlERFRE8FARE4hPMAT/x7bHR+O7oZgjRrnrl7HqI/346X/HYWxpFzu8oiIqJFjICKnoVAoENdeh9Rpf0JCj3AAwOpDFxD79i5sPZ4jc3VERNSYMRCR09G4u+HNYTH4YkJPtLox6Drxvz8g8T8ZyDWVyl0eERE1QgxE5LR6tArAN8/3waT+kXBVKrD1hAGxb+/ClxkXOUWfiIjsioGInJq7mwteiIvCxkm90bG5FoWlFXhh7RFM+E8GLhea5S6PiIgaCQYiahCiQzVYN/EBzIiLgpuLAqk/5mLgol345hjHFhERUd0xEFGD4eqiRFL/SGyc1BvtQjS4dr0cz638AX/7/DAKrpfJXR4RETVgDETU4LQL0eCrpF6Y1D8SSgWw8cglDFy0GztO5sldGhERNVAMRNQgqVyVeCEuCv+b+ABaNfNCXqEZTycfwtyNJ7jKNRER2YyBiBq0LuF++OZvffB0r5YAgOR95zD0/b34OZfPRCMioppjIKIGz93NBa8+3B7Ln7oPAV4qnDQU4qH39uC/+89zej4REdUIAxE1Gv3bBmHLlD7o0yYQ5goLZm84jsT/ZnDANRER3RUDETUqQT7uWPH0/Xh5SDu4uSiQciIXg975DofO5ctdGhEROTEGImp0lEoFnu3bCusm9kJEoBcMplKM/Gg/PvnuF95CIyKiW2IgokYrprkWmyb3xiOdQlFpEXhj80+Y+N8fYCotl7s0IiJyMgxE1Kh5qV2xeGRnvP5oe7i5VD0P7ZH39uDHSya5SyMiIifi1IFo7ty5UCgUVq+2bdtK+0tLS5GUlISAgAB4e3tjxIgRyM3NtTpGdnY24uPj4enpiaCgIMyYMQMVFRX1fSokI4VCgdH6llib+ADu8fXAuavXMeyDvVj7/QW5SyMiIifh1IEIANq3b4+cnBzptWfPHmnf1KlT8fXXX2Pt2rXYtWsXLl26hOHDh0v7KysrER8fj7KyMuzbtw8rVqxAcnIy5syZI8epkMw6h/li0+Te6BfVDOYKC2Z8eRSz1h1DWYVF7tKIiEhmCuHEo0znzp2LDRs2IDMz86Z9RqMRzZo1w6pVq/DYY48BAE6ePIl27dohPT0dPXv2xJYtW/DQQw/h0qVLCA4OBgAsW7YMM2fOxOXLl6FSqWpUh8lkglarhdFohEajsdv5kTwsFoH3d5zG29tOQQigews/LH2yG5r5qOUujYiI7MiW72+n7yH6+eefERoailatWiEhIQHZ2dkAgIyMDJSXlyM2NlZq27ZtW4SHhyM9PR0AkJ6ejpiYGCkMAUBcXBxMJhNOnDhx2880m80wmUxWL2o8lEoFJg9og0+fug8+7q74/vw1PLJkD45eLJC7NCIikolTB6IePXogOTkZW7duxdKlS3H27Fn06dMHhYWFMBgMUKlU8PX1tfqd4OBgGAwGAIDBYLAKQ9X7q/fdzrx586DVaqVXWFiYfU+MnEL/qCB8ldQLrZp5IcdYir8sS8eGw7/KXRYREcnAqQPR4MGD8Ze//AUdO3ZEXFwcvvnmGxQUFGDNmjUO/dxZs2bBaDRKrwsXOPi2sWrVzBsbknrhwbZBMFdYMOWLTMz75idUWpz2TjIRETmAUweiP/L19cW9996L06dPQ6fToaysDAUFBVZtcnNzodPpAAA6ne6mWWfV76vb3IparYZGo7F6UeOlcXfDx2O647l+rQEAH+7+BeOSD3G9IiKiJqRBBaKioiKcOXMGISEh6NatG9zc3JCWlibtz8rKQnZ2NvR6PQBAr9fj2LFjyMvLk9qkpqZCo9EgOjq63usn5+WiVODFQW3x3qgucHdTYtepy/jL0nT8WlAid2lERFQPnDoQvfDCC9i1axfOnTuHffv2YdiwYXBxccGoUaOg1Woxfvx4TJs2DTt27EBGRgaefvpp6PV69OzZEwAwcOBAREdHY/To0Thy5AhSUlIwe/ZsJCUlQa3mjCK62cOdQrH2/z2AZj5qZOUWYuj7eznYmoioCXDqQHTx4kWMGjUKUVFR+Otf/4qAgADs378fzZo1AwAsWrQIDz30EEaMGIG+fftCp9Nh3bp10u+7uLhg06ZNcHFxgV6vx5NPPokxY8bgtddek+uUqAGIaa7FhqReaKvzweVCM/76YTpSTtx+ED4RETV8Tr0OkbPgOkRNU2FpOSatOoxdpy5DoQBeHtIO43tHQKFQyF0aERHVQKNah4hILj7ubvj32O5I6BEOIYA3Nv+E2RuOo6KSK1sTETU2DEREd+DqosQbQztgdnw7KBTAygPZeOaz71Fs5vPwiIgaEwYiortQKBR4pk8rLHuyG9zdlNiZdRlPfLwfV4vMcpdGRER2wkBEVENx7XVY9WxP+Hm64chFI0Ys3Yfsq9flLouIiOyAgYjIBl3D/fDlxAfQ3M8D565ex/Cle3HsolHusoiIqI4YiIhs1LqZN9ZNfADtQjS4UlSGkR+l47ufL8tdFhER1QEDEVEtBGncseb/9USvyAAUl1Xi6eWHsP7wRbnLIiKiWmIgIqolH3c3LH/qfjzSKRQVFoGpXxzBh7vOgEt7ERE1PAxERHWgclXincc745neEQCAeVtO4rVNP8JiYSgiImpIGIiI6kipVGD2Q9F4eUg7AMDyvefwt9WHYa6olLkyIiKqKQYiIjt5tm8rLB7ZGW4uCmw6moOnlx9CYWm53GUREVENMBAR2dGjne/B8qfuh5fKBfvOXMVfP9yPPFOp3GUREdFdMBAR2VnvNoH44v/pEeitxk85Jgxfug9nLhfJXRYREd0BAxGRA3S4R4t1Ex9AywBPXLxWgseW7sPh7Gtyl0VERLfBQETkIOEBnvhy4gPo1FyLa9fL8cTHB7D9ZK7cZRER0S0wEBE5UKC3Gque7Yk/3dsMJeWVePazDKz5/oLcZRER0R8wEBE5mJfaFZ+M7Y7hXe9BpUXgxS+P4v0dp7mAIxGRE2EgIqoHbi5KvPWXTpjYrzUAYGFKFl7deAKVXMCRiMgpMBAR1ROFQoGZg9pi7sPRUCiAz9LPY9KqH1BazgUciYjkxkBEVM+e6hWBJaO6QuWixJbjBoz59CCMJVzAkYhITgxERDKI7xiCFePuh4/aFQfP5uOvy9JxIf+63GURETVZDEREMtG3DsCaRD2CfNTIyi3E0Pf34tC5fLnLIiJqkhiIiGTULkSDryb1QvtQDa4WlyHh4wP4MuOi3GURETU5DEREMgvRemBtoh6DO+hQVmnBC2uPYN43P3EGGhFRPWIgInICnipXvP9EV0x+MBIA8OHuXzDhs+852JqIqJ4wEBE5CaVSgekDo7B4ZGeoXJVIO5mHR5bswYlLRrlLIyJq9BiIiJzMo53vwf8SH0BzPw+cv3odwz/YhzWH+LgPIiJHYiAickIxzbXYNLk3HmwbBHOFBS/+7yhmrD2CYnOF3KURETVKDERETsrXU4VPxnTHjLgoKBXA2oyLiH/3O/yQfU3u0oiIGh0GIiInplQqkNQ/Eiuf6YlQrTvOXb2OvyxLx9upp1BeaZG7PCKiRoOBiKgB0LcOwJYpfTG0cygqLQLvpv2MR5fsReaFArlLIyJqFBiIiBoIrYcb3hnZBe+N6gKthxt+zDFh2Ad7Meer4zCVcno+EVFdMBARNTAPdwpF2vQ/YXiXeyAE8Fn6ecS+tQtrDl3gYo5ERLWkEELwX9C7MJlM0Gq1MBqN0Gg0cpdDJNl7+gpmbziOs1eKAQBRwT54aXBb9ItqBoVCIXN1RETysuX7m4GoBhiIyJmZKyrxn/TzeG/7aWll605hvniuX2v8uV0wlEoGIyJqmhiI7IyBiBoC4/VyvL/zNFbsOwdzRdUMtDZB3niqV0s82vkeeKtdZa6QiKh+MRDZGQMRNSSXC81Yvvcs/pN+HoU3FnL0VLng0c6hGNG1ObqG+7HXiIiaBAYiO2MgoobIVFqONYcuYNXBbPxyuVjaHqxRY3CHEAyMDkbXFn5wd3ORsUoiIsdhILqN999/HwsXLoTBYECnTp3w3nvv4f7777/r7zEQUUMmhMDBs/n44tAFpP6YK/UaAYDKVYnuLfzQKzIQncN80SFUC62nm4zVEhHZDwPRLXzxxRcYM2YMli1bhh49euCdd97B2rVrkZWVhaCgoDv+LgMRNRbmikrsPX0F3xwz4LufLyPXZL6pTbi/J9qF+KBloBciArzQIsAL4QGeCPRWQe3K3iQiajgYiG6hR48euO+++7BkyRIAgMViQVhYGCZPnoyXXnrpjr/LQESNkRACZy4XY9+ZK9j/y1Uc+9WIC/kld/wdrYcbAr1VaOajhr+XCl4qV3ipXeGtrv7TBR4qV7i5KODmooSbixKuLgqofvezm1KJ6hUBFApAAQWUyqo/q94DCoX1z0rFb/up4eHfG9WEi1KBEK2HXY9py/d3k5h2UlZWhoyMDMyaNUvaplQqERsbi/T09Jvam81mmM2//Z+zyWSqlzqJ6pNCoUBkkDcig7wxRt8SQNVMteOXjDiVW4jzV6/j7JVinL9ajF8LSlBeKWAsKYexpBxnfjcmiYjIHoJ81Dj4cqxsn98kAtGVK1dQWVmJ4OBgq+3BwcE4efLkTe3nzZuHf/zjH/VVHpHT0Hq6oVdkIHpFBlptF6IqDF0uNONykRmXC80ouF6OInMFim+8isyVKDZXoKS8EhUWC8orBMotFpRXWv9cUSkgBCBQ/Seq/hTixs9Vf1osVX/iRhuLqGrfGN0400apsf6dkf2p3eR9eEaTCES2mjVrFqZNmya9N5lMCAsLk7EiInkpFAr4eqrg66lCm2AfucshIrK7JhGIAgMD4eLigtzcXKvtubm50Ol0N7VXq9VQq9X1VR4RERHJrEk83FWlUqFbt25IS0uTtlksFqSlpUGv18tYGRERETmDJtFDBADTpk3D2LFj0b17d9x///145513UFxcjKefflru0oiIiEhmTSYQPf7447h8+TLmzJkDg8GAzp07Y+vWrTcNtCYiIqKmp8msQ1QXXIeIiIio4bHl+7tJjCEiIiIiuhMGIiIiImryGIiIiIioyWMgIiIioiaPgYiIiIiaPAYiIiIiavIYiIiIiKjJYyAiIiKiJo+BiIiIiJq8JvPojrqoXszbZDLJXAkRERHVVPX3dk0eysFAVAOFhYUAgLCwMJkrISIiIlsVFhZCq9XesQ2fZVYDFosFly5dgo+PDxQKhV2PbTKZEBYWhgsXLvA5aQ7E61w/eJ3rD691/eB1rh+Ous5CCBQWFiI0NBRK5Z1HCbGHqAaUSiWaN2/u0M/QaDT8j60e8DrXD17n+sNrXT94neuHI67z3XqGqnFQNRERETV5DERERETU5DEQyUytVuPVV1+FWq2Wu5RGjde5fvA61x9e6/rB61w/nOE6c1A1ERERNXnsISIiIqImj4GIiIiImjwGIiIiImryGIiIiIioyWMgktH777+Pli1bwt3dHT169MDBgwflLqlBmTdvHu677z74+PggKCgIQ4cORVZWllWb0tJSJCUlISAgAN7e3hgxYgRyc3Ot2mRnZyM+Ph6enp4ICgrCjBkzUFFRUZ+n0qDMnz8fCoUCU6ZMkbbxOtvPr7/+iieffBIBAQHw8PBATEwMvv/+e2m/EAJz5sxBSEgIPDw8EBsbi59//tnqGPn5+UhISIBGo4Gvry/Gjx+PoqKi+j4Vp1VZWYlXXnkFERER8PDwQOvWrfH6669bPe+K19l2u3fvxsMPP4zQ0FAoFAps2LDBar+9runRo0fRp08fuLu7IywsDAsWLLDPCQiSxerVq4VKpRKffvqpOHHihHj22WeFr6+vyM3Nlbu0BiMuLk4sX75cHD9+XGRmZoohQ4aI8PBwUVRUJLVJTEwUYWFhIi0tTXz//feiZ8+e4oEHHpD2V1RUiA4dOojY2Fhx+PBh8c0334jAwEAxa9YsOU7J6R08eFC0bNlSdOzYUTz//PPSdl5n+8jPzxctWrQQTz31lDhw4ID45ZdfREpKijh9+rTUZv78+UKr1YoNGzaII0eOiEceeURERESIkpISqc2gQYNEp06dxP79+8V3330nIiMjxahRo+Q4Jaf05ptvioCAALFp0yZx9uxZsXbtWuHt7S0WL14steF1tt0333wjXn75ZbFu3ToBQKxfv95qvz2uqdFoFMHBwSIhIUEcP35cfP7558LDw0N8+OGHda6fgUgm999/v0hKSpLeV1ZWitDQUDFv3jwZq2rY8vLyBACxa9cuIYQQBQUFws3NTaxdu1Zq89NPPwkAIj09XQhR9R+wUqkUBoNBarN06VKh0WiE2Wyu3xNwcoWFhaJNmzYiNTVV/OlPf5ICEa+z/cycOVP07t37tvstFovQ6XRi4cKF0raCggKhVqvF559/LoQQ4scffxQAxKFDh6Q2W7ZsEQqFQvz666+OK74BiY+PF+PGjbPaNnz4cJGQkCCE4HW2hz8GIntd0w8++ED4+flZ/bsxc+ZMERUVVeeaectMBmVlZcjIyEBsbKy0TalUIjY2Funp6TJW1rAZjUYAgL+/PwAgIyMD5eXlVte5bdu2CA8Pl65zeno6YmJiEBwcLLWJi4uDyWTCiRMn6rF655eUlIT4+Hir6wnwOtvTxo0b0b17d/zlL39BUFAQunTpgo8//ljaf/bsWRgMBqtrrdVq0aNHD6tr7evri+7du0ttYmNjoVQqceDAgfo7GSf2wAMPIC0tDadOnQIAHDlyBHv27MHgwYMB8Do7gr2uaXp6Ovr27QuVSiW1iYuLQ1ZWFq5du1anGvlwVxlcuXIFlZWVVl8OABAcHIyTJ0/KVFXDZrFYMGXKFPTq1QsdOnQAABgMBqhUKvj6+lq1DQ4OhsFgkNrc6u+heh9VWb16NX744QccOnTopn28zvbzyy+/YOnSpZg2bRr+/ve/49ChQ/jb3/4GlUqFsWPHStfqVtfy99c6KCjIar+rqyv8/f15rW946aWXYDKZ0LZtW7i4uKCyshJvvvkmEhISAIDX2QHsdU0NBgMiIiJuOkb1Pj8/v1rXyEBEjUJSUhKOHz+OPXv2yF1Ko3PhwgU8//zzSE1Nhbu7u9zlNGoWiwXdu3fHP//5TwBAly5dcPz4cSxbtgxjx46VubrGY82aNVi5ciVWrVqF9u3bIzMzE1OmTEFoaCivcxPGW2YyCAwMhIuLy02zcHJzc6HT6WSqquGaNGkSNm3ahB07dqB58+bSdp1Oh7KyMhQUFFi1//111ul0t/x7qN5HVbfE8vLy0LVrV7i6usLV1RW7du3Cu+++C1dXVwQHB/M620lISAiio6OttrVr1w7Z2dkAfrtWd/q3Q6fTIS8vz2p/RUUF8vPzea1vmDFjBl566SWMHDkSMTExGD16NKZOnYp58+YB4HV2BHtdU0f+W8JAJAOVSoVu3bohLS1N2maxWJCWlga9Xi9jZQ2LEAKTJk3C+vXrsX379pu6Ubt16wY3Nzer65yVlYXs7GzpOuv1ehw7dszqP8LU1FRoNJqbvpiaqgEDBuDYsWPIzMyUXt27d0dCQoL0M6+zffTq1eumpSNOnTqFFi1aAAAiIiKg0+msrrXJZMKBAwesrnVBQQEyMjKkNtu3b4fFYkGPHj3q4Syc3/Xr16FUWn/9ubi4wGKxAOB1dgR7XVO9Xo/du3ejvLxcapOamoqoqKg63S4DwGn3clm9erVQq9UiOTlZ/Pjjj2LChAnC19fXahYO3dnEiROFVqsVO3fuFDk5OdLr+vXrUpvExEQRHh4utm/fLr7//nuh1+uFXq+X9ldPBx84cKDIzMwUW7duFc2aNeN08Lv4/SwzIXid7eXgwYPC1dVVvPnmm+Lnn38WK1euFJ6enuK///2v1Gb+/PnC19dXfPXVV+Lo0aPi0UcfveXU5S5duogDBw6IPXv2iDZt2jTp6eB/NHbsWHHPPfdI0+7XrVsnAgMDxYsvvii14XW2XWFhoTh8+LA4fPiwACDefvttcfjwYXH+/HkhhH2uaUFBgQgODhajR48Wx48fF6tXrxaenp6cdt/QvffeeyI8PFyoVCpx//33i/3798tdUoMC4Jav5cuXS21KSkrEc889J/z8/ISnp6cYNmyYyMnJsTrOuXPnxODBg4WHh4cIDAwU06dPF+Xl5fV8Ng3LHwMRr7P9fP3116JDhw5CrVaLtm3bio8++shqv8ViEa+88ooIDg4WarVaDBgwQGRlZVm1uXr1qhg1apTw9vYWGo1GPP3006KwsLA+T8OpmUwm8fzzz4vw8HDh7u4uWrVqJV5++WWrqdy8zrbbsWPHLf9NHjt2rBDCftf0yJEjonfv3kKtVot77rlHzJ8/3y71K4T43dKcRERERE0QxxARERFRk8dARERERE0eAxERERE1eQxERERE1OQxEBEREVGTx0BERERETR4DERERETV5DERERETU5DEQERHVkkKhwIYNG+Qug4jsgIGIiBqkp556CgqF4qbXoEGD5C6NiBogV7kLICKqrUGDBmH58uVW29RqtUzVEFFDxh4iImqw1Go1dDqd1cvPzw9A1e2spUuXYvDgwfDw8ECrVq3w5ZdfWv3+sWPH8OCDD8LDwwMBAQGYMGECioqKrNp8+umnaN++PdRqNUJCQjBp0iSr/VeuXMGwYcPg6emJNm3aYOPGjY49aSJyCAYiImq0XnnlFYwYMQJHjhxBQkICRo4ciZ9++gkAUFxcjLi4OPj5+eHQoUNYu3Yttm3bZhV4li5diqSkJEyYMAHHjh3Dxo0bERkZafUZ//jHP/DXv/4VR48exZAhQ5CQkID8/Px6PU8isgNBRNQAjR07Vri4uAgvLy+r15tvvimEEAKASExMtPqdHj16iIkTJwohhPjoo4+En5+fKCoqkvZv3rxZKJVKYTAYhBBChIaGipdffvm2NQAQs2fPlt4XFRUJAGLLli12O08iqh8cQ0REDVb//v2xdOlSq23+/v7Sz3q93mqfXq9HZmYmAOCnn35Cp06d4OXlJe3v1asXLBYLsrKyoFAocOnSJQwYMOCONXTs2FH62cvLCxqNBnl5ebU9JSKSCQMRETVYXl5eN93CshcPD48atXNzc7N6r1AoYLFYHFESETkQxxARUaO1f//+m963a9cOANCuXTscOXIExcXF0v69e/dCqVQiKioKPj4+aNmyJdLS0uq1ZiKSB3uIiKjBMpvNMBgMVttcXV0RGBgIAFi7di26d++O3r17Y+XKlTh48CD+/e9/AwASEhLw6quvYuzYsZg7dy4uX76MyZMnY/To0QgODgYAzJ07F4mJiQgKCsLgwYNRWFiIvXv3YvLkyfV7okTkcAxERNRgbd26FSEhIVbboqKicPLkSQBVM8BWr16N5557DiEhIfj8888RHR0NAPD09ERKSgqef/553HffffD09MSIESPw9ttvS8caO3YsSktLsWjRIrzwwgsIDAzEY489Vn8nSET1RiGEEHIXQURkbwqFAuvXr8fQoUPlLoWIGgCOISIiIqImj4GIiIiImjyOISKiRomjAYjIFuwhIiIioiaPgYiIiIiaPAYiIiIiavIYiIiIiKjJYyAiIiKiJo+BiIiIiJo8BiIiIiJq8hiIiIiIqMn7/4aAOHuA7t5WAAAAAElFTkSuQmCC\n"},"metadata":{}}]},{"cell_type":"markdown","source":["From this plot it is possible to note that approximately from the epoch 300 or 400, the loss function is so small that it presents no substancial changes (i.e. from the epoch 400 the algorithm foes not learn anything more).\n"],"metadata":{"id":"iMHzI4z-UB1Y"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"F13j0jRWktyQ"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"FXzcLroVR3J3"}}]}